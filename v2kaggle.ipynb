{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7315223,"sourceType":"datasetVersion","datasetId":4105007}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"id":"dm0vUHFiEtxF","outputId":"40f08354-8b24-4491-83b9-c69690c0ae77","execution":{"iopub.status.busy":"2024-01-01T04:12:12.146341Z","iopub.execute_input":"2024-01-01T04:12:12.146716Z","iopub.status.idle":"2024-01-01T04:12:26.159879Z","shell.execute_reply.started":"2024-01-01T04:12:12.146678Z","shell.execute_reply":"2024-01-01T04:12:26.158985Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import GPT2Model, GPT2Config\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt","metadata":{"id":"-wLjihQUEk1l","execution":{"iopub.status.busy":"2024-01-01T04:15:09.637341Z","iopub.execute_input":"2024-01-01T04:15:09.637708Z","iopub.status.idle":"2024-01-01T04:15:18.883031Z","shell.execute_reply.started":"2024-01-01T04:15:09.637685Z","shell.execute_reply":"2024-01-01T04:15:18.882254Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"Zp6qkDfiF831","execution":{"iopub.status.busy":"2024-01-01T04:24:03.756399Z","iopub.execute_input":"2024-01-01T04:24:03.756986Z","iopub.status.idle":"2024-01-01T04:24:03.832620Z","shell.execute_reply.started":"2024-01-01T04:24:03.756954Z","shell.execute_reply":"2024-01-01T04:24:03.831567Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"A = 5 # number of actions\nN = 40000 # number of offline datasets\nn = 500 # context length\ntrials = 500 # online regret trials for val/test","metadata":{"id":"vaz-CdtzEr_4","execution":{"iopub.status.busy":"2024-01-01T04:24:04.261275Z","iopub.execute_input":"2024-01-01T04:24:04.261576Z","iopub.status.idle":"2024-01-01T04:24:04.265710Z","shell.execute_reply.started":"2024-01-01T04:24:04.261551Z","shell.execute_reply":"2024-01-01T04:24:04.264809Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def generate_B(A=5, N=40000, n=500):\n    dsets, actions = [], []\n    for i in tqdm(range(N)):\n        mu = np.random.rand(A)\n\n        p_1 = np.random.dirichlet(np.ones(A))\n        p_2 = np.zeros(A)\n        p_2[np.random.choice(A)] = 1\n        w = (np.random.choice(11)) / 10\n        p = (1 - w) * p_1 + w * p_2\n\n        a = np.random.choice(A, n, p=p)\n        actions.append(a)\n\n        r = np.random.normal(mu[a], 0.3)\n\n        X = np.zeros((n, A + 3), np.float32)\n        X[:, [0, -2]] = 1\n        X[np.arange(n), a + 1] = 1\n        X[:, -1] = r\n        dsets.append(X)\n    return dsets, actions","metadata":{"id":"3rbBQaMXE0vu","execution":{"iopub.status.busy":"2024-01-01T04:24:04.815013Z","iopub.execute_input":"2024-01-01T04:24:04.815348Z","iopub.status.idle":"2024-01-01T04:24:04.823750Z","shell.execute_reply.started":"2024-01-01T04:24:04.815323Z","shell.execute_reply":"2024-01-01T04:24:04.822872Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class BanditDataset(Dataset):\n    def __init__(self, dsets, actions):\n        self.dsets = dsets\n        self.actions = actions\n\n        self.first = np.zeros((1, A + 3), dtype=np.float32)\n        self.first[0, 0] = 1\n\n    def __len__(self):\n        return len(self.dsets)\n\n    def __getitem__(self, idx):\n        perm = np.random.permutation(n) # shuffled in-context datset to reduce overfitting\n        sample_ds = np.concatenate((self.first, self.dsets[idx][perm]))\n        return sample_ds, self.actions[idx][perm]","metadata":{"id":"KrkrrD4SE8p0","execution":{"iopub.status.busy":"2024-01-01T04:24:05.303483Z","iopub.execute_input":"2024-01-01T04:24:05.303810Z","iopub.status.idle":"2024-01-01T04:24:05.310302Z","shell.execute_reply.started":"2024-01-01T04:24:05.303783Z","shell.execute_reply":"2024-01-01T04:24:05.309415Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class TransformerModel(nn.Module):\n    def __init__(self, n_states, n_positions=501, n_embd=32, n_layer=4, n_head=4):\n        super(TransformerModel, self).__init__()\n        configuration = GPT2Config(\n            n_positions=n_positions,\n            n_embd=n_embd,\n            n_layer=n_layer,\n            n_head=n_head,\n        )\n        self.name = f\"gpt2_embd={n_embd}_layer={n_layer}_head={n_head}\"\n\n        self.n_positions = n_positions\n        self.n_dims = n_states\n        self._read_in = nn.Linear(n_states + 3, n_embd)\n        self._backbone = GPT2Model(configuration)\n        self._read_out = nn.Linear(n_embd, n_states)\n        self._flatten = nn.Flatten(0, 1)\n\n        for w in self._backbone.wpe.parameters(): # remove positional embedding\n            w.data.fill_(0)\n        self._backbone.wpe.weight.requires_grad=False\n\n    def forward(self, X):\n        embeds = self._read_in(X)\n        output = self._backbone(inputs_embeds=embeds).last_hidden_state\n        logit = self._read_out(output)[:, :-1]\n        logit = self._flatten(logit)\n        return logit","metadata":{"id":"wD1smOF4E_5n","execution":{"iopub.status.busy":"2024-01-01T04:24:05.769559Z","iopub.execute_input":"2024-01-01T04:24:05.769946Z","iopub.status.idle":"2024-01-01T04:24:05.779677Z","shell.execute_reply.started":"2024-01-01T04:24:05.769914Z","shell.execute_reply":"2024-01-01T04:24:05.778659Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dsets_train, actions_train = generate_B(N=N)\ndsets_val, actions_val = generate_B(N=N//4)\n\ndata_train = BanditDataset(dsets_train, actions_train)\ndata_val = BanditDataset(dsets_val, actions_val)\n\ntrain_dataloader = DataLoader(data_train, batch_size=64)\nval_dataloader = DataLoader(data_val, batch_size=64)","metadata":{"id":"JaOb-DhyFHJZ","outputId":"d10e0350-9d69-445e-b54b-1c9e889110ea","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(dsets_train, 'dsets_train.pth')\ntorch.save(dsets_val, 'dsets_val.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(actions_train, 'actions_train.pth')\ntorch.save(actions_val, 'actions_val.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dsets_train = torch.load('/kaggle/input/bandit-data1/dsets_train.pth')\ndsets_val = torch.load('/kaggle/input/bandit-data1/dsets_val.pth')","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:24:10.017730Z","iopub.execute_input":"2024-01-01T04:24:10.018645Z","iopub.status.idle":"2024-01-01T04:24:21.483207Z","shell.execute_reply.started":"2024-01-01T04:24:10.018610Z","shell.execute_reply":"2024-01-01T04:24:21.482395Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"actions_train = torch.load('/kaggle/input/bandit-data1/actions_train.pth')\nactions_val = torch.load('/kaggle/input/bandit-data1/actions_val.pth')","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:24:21.486302Z","iopub.execute_input":"2024-01-01T04:24:21.486576Z","iopub.status.idle":"2024-01-01T04:24:23.731226Z","shell.execute_reply.started":"2024-01-01T04:24:21.486552Z","shell.execute_reply":"2024-01-01T04:24:23.730230Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data_train = BanditDataset(dsets_train, actions_train)\ndata_val = BanditDataset(dsets_val, actions_val)\n\ntrain_dataloader = DataLoader(data_train, batch_size=64)\nval_dataloader = DataLoader(data_val, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:24:23.733806Z","iopub.execute_input":"2024-01-01T04:24:23.734131Z","iopub.status.idle":"2024-01-01T04:24:23.739367Z","shell.execute_reply.started":"2024-01-01T04:24:23.734106Z","shell.execute_reply":"2024-01-01T04:24:23.738551Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = TransformerModel(n_states=A)\nmodel.to(device)\nmodel = nn.DataParallel(model)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n#optimizer = torch.optim.AdamW([param for param in model.parameters() if param.requires_grad == True])","metadata":{"id":"auCE_VMpFkl5","execution":{"iopub.status.busy":"2024-01-01T04:25:22.473607Z","iopub.execute_input":"2024-01-01T04:25:22.474284Z","iopub.status.idle":"2024-01-01T04:25:27.408014Z","shell.execute_reply.started":"2024-01-01T04:25:22.474247Z","shell.execute_reply":"2024-01-01T04:25:27.407187Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Train Initial Policy","metadata":{"id":"vO7Chq67BfOo"}},{"cell_type":"code","source":"def train_initial_policy(model, data_loader, optimizer):\n    size = len(data_loader.dataset)\n    model.train()\n    for batch, (X, a) in enumerate(train_dataloader):\n        X = X.to(device)\n        pred = model(X)\n        a = a.flatten().to(device)\n\n        loss_fn = torch.nn.CrossEntropyLoss()\n        loss = torch.mean(loss_fn(pred, a))\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), (batch + 1) * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")","metadata":{"id":"i2CloUmT7JLZ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_initial_policy(model, dataloader):\n    num_batches = len(dataloader)\n    model.eval()\n    val_loss = 0\n\n    with torch.no_grad():\n        for X, a in dataloader:\n            X = X.to(device)\n            pred = model(X)\n            a = a.flatten().to(device)\n\n            loss_fn = torch.nn.CrossEntropyLoss()\n            loss = torch.mean(loss_fn(pred, a))\n            val_loss += loss.item()\n\n    val_loss /= num_batches\n    print(f\"Val loss: {val_loss:>8f} \\n\")\n    return val_loss","metadata":{"id":"sTSAVwU2Pa9q","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nnp.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\ncur_val_loss = np.inf\ncur_epoch = 1\ncur_state_dict = None\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train_initial_policy(model, train_dataloader, optimizer)\n    if test_initial_policy(model, val_dataloader) < cur_val_loss:\n        cur_epoch = t + 1\n        cur_state_dict = model.module.state_dict()\n        torch.save({\n            'epoch': cur_epoch,\n            'model_state_dict': cur_state_dict,\n            }, 'transformer_model.pt')\nprint(\"Done!\")","metadata":{"id":"C-gE2Re-Po9m","outputId":"32e70cfe-13f9-49ba-9246-4cff33438c66","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'initial_policy.pth')","metadata":{"id":"brGHYYCKovX4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/input/bandit-data1/initial_policy.pth'))\nmodel.to(device)","metadata":{"id":"YYaEXmHU41aI","outputId":"6c72164d-1028-40fb-902c-835f57cb094f","execution":{"iopub.status.busy":"2024-01-01T04:25:32.433990Z","iopub.execute_input":"2024-01-01T04:25:32.434354Z","iopub.status.idle":"2024-01-01T04:25:32.659942Z","shell.execute_reply.started":"2024-01-01T04:25:32.434327Z","shell.execute_reply":"2024-01-01T04:25:32.659041Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): TransformerModel(\n    (_read_in): Linear(in_features=8, out_features=32, bias=True)\n    (_backbone): GPT2Model(\n      (wte): Embedding(50257, 32)\n      (wpe): Embedding(501, 32)\n      (drop): Dropout(p=0.1, inplace=False)\n      (h): ModuleList(\n        (0-3): 4 x GPT2Block(\n          (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n          (attn): GPT2Attention(\n            (c_attn): Conv1D()\n            (c_proj): Conv1D()\n            (attn_dropout): Dropout(p=0.1, inplace=False)\n            (resid_dropout): Dropout(p=0.1, inplace=False)\n          )\n          (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n          (mlp): GPT2MLP(\n            (c_fc): Conv1D()\n            (c_proj): Conv1D()\n            (act): NewGELUActivation()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (ln_f): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n    )\n    (_read_out): Linear(in_features=32, out_features=5, bias=True)\n    (_flatten): Flatten(start_dim=0, end_dim=1)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def generate(A=5, N=1, n=500):\n    mu = np.random.rand(A)\n\n    p_1 = np.random.dirichlet(np.ones(A))\n    p_2 = np.zeros(A)\n    p_2[np.random.choice(A)] = 1\n    w = (np.random.choice(11)) / 10\n    p = (1 - w) * p_1 + w * p_2\n\n    a = np.random.choice(A, n, p=p)\n\n    r = np.random.normal(mu[a], 0.3)\n\n    X = np.zeros((n, A + 3), np.float32)\n    X[:, [0, -2]] = 1\n    X[np.arange(n), a + 1] = 1\n    X[:, -1] = r\n    return X, mu","metadata":{"id":"2ZoZulnOvlzA","execution":{"iopub.status.busy":"2024-01-01T04:25:40.547523Z","iopub.execute_input":"2024-01-01T04:25:40.548505Z","iopub.status.idle":"2024-01-01T04:25:40.555373Z","shell.execute_reply.started":"2024-01-01T04:25:40.548465Z","shell.execute_reply":"2024-01-01T04:25:40.554534Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"reg = np.empty((500, n - 1))\n\nfor trial in range(500):\n  X, mu = generate()\n  X = torch.unsqueeze(torch.from_numpy(X).to(device), 0)\n  with torch.no_grad():\n    prediction = model.forward(X).cpu().numpy()\n  reg[trial] = np.max(mu) - mu[prediction.argmax(1)]","metadata":{"id":"XVDQSafH1alD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, mu = generate()\nX = torch.unsqueeze(torch.from_numpy(X).to(device), 0)\nwith torch.no_grad():\n  prediction = model.forward(X).cpu().numpy()","metadata":{"id":"zJ_yxN8zbsY-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Q function: Q(a) = E(Rt|At=a)","metadata":{"id":"zaNP1SCqBhZt"}},{"cell_type":"code","source":"def select_action_with_policy(model, X):\n    X = torch.unsqueeze(torch.from_numpy(X).to(device), 0)\n    with torch.no_grad():\n        predictions = model.forward(X).cpu().numpy()\n    return predictions","metadata":{"id":"9IoY03kHBjVA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Q_function(dsets, actions, N=N):\n    Q_est = np.zeros((N, A))\n\n    for trial in tqdm(range(N)):\n        Qa = np.zeros(A)\n        Na = np.zeros(A)\n\n        X = dsets[trial]\n        a = actions[trial]\n\n        for i in range(n):\n            reward = X[i, -1]\n            action = a[i]\n\n            Na[action] += 1\n            Qa[action] += reward\n        \n        Q_est[trial] = np.nan_to_num(Qa / Na)\n\n    return Q_est","metadata":{"id":"be7zRscqk8Kn","execution":{"iopub.status.busy":"2023-12-31T23:31:31.884900Z","iopub.execute_input":"2023-12-31T23:31:31.885303Z","iopub.status.idle":"2023-12-31T23:31:31.892027Z","shell.execute_reply.started":"2023-12-31T23:31:31.885271Z","shell.execute_reply":"2023-12-31T23:31:31.890974Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"# Q_est_train = e_greedy_k_armed_bandit_with_policy(model, dsets_train)\n# Q_est_val = e_greedy_k_armed_bandit_with_policy(model, dsets_val, N=N//4)\n\nQ_est_train = Q_function(dsets_train, actions_train)\nQ_est_val = Q_function(dsets_val, actions_val, N=N//4)","metadata":{"id":"ZmuGaJ3Nk80x","outputId":"15ec3d67-718a-461e-e0b4-36cff658473e","execution":{"iopub.status.busy":"2023-12-31T23:31:32.854463Z","iopub.execute_input":"2023-12-31T23:31:32.855186Z","iopub.status.idle":"2023-12-31T23:32:27.246639Z","shell.execute_reply.started":"2023-12-31T23:31:32.855150Z","shell.execute_reply":"2023-12-31T23:32:27.245650Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stderr","text":"  0%|          | 0/40000 [00:00<?, ?it/s]/tmp/ipykernel_103/3391818274.py:18: RuntimeWarning: invalid value encountered in divide\n  Q_est[trial] = np.nan_to_num(Qa / Na)\n100%|██████████| 40000/40000 [00:43<00:00, 917.44it/s]\n100%|██████████| 10000/10000 [00:10<00:00, 927.75it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(Q_est_train, 'Q_est_train.pth')\ntorch.save(Q_est_val, 'Q_est_val.pth')","metadata":{"id":"eh7BHFrC05Ag","execution":{"iopub.status.busy":"2023-12-31T23:32:48.623091Z","iopub.execute_input":"2023-12-31T23:32:48.623825Z","iopub.status.idle":"2023-12-31T23:32:48.648682Z","shell.execute_reply.started":"2023-12-31T23:32:48.623787Z","shell.execute_reply":"2023-12-31T23:32:48.647582Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"Q_est_train = torch.load('/kaggle/input/bandit-data1/Q_est_train-2.pth')\nQ_est_val = torch.load('/kaggle/input/bandit-data1/Q_est_val-2.pth')","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:25:52.744991Z","iopub.execute_input":"2024-01-01T04:25:52.745357Z","iopub.status.idle":"2024-01-01T04:25:52.806579Z","shell.execute_reply.started":"2024-01-01T04:25:52.745327Z","shell.execute_reply":"2024-01-01T04:25:52.805645Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Policy Improvement","metadata":{"id":"v2G_BYkWQiJ9"}},{"cell_type":"code","source":"init_model = TransformerModel(n_states=A)\ninit_model.to(device)\ninit_model = nn.DataParallel(init_model)\ninit_model.load_state_dict(torch.load('/kaggle/input/bandit-data1/initial_policy.pth'))","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:25:55.122959Z","iopub.execute_input":"2024-01-01T04:25:55.123609Z","iopub.status.idle":"2024-01-01T04:25:55.186196Z","shell.execute_reply.started":"2024-01-01T04:25:55.123573Z","shell.execute_reply":"2024-01-01T04:25:55.185325Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"initial_train_probs = []\nwith torch.no_grad():\n    for X, _ in train_dataloader:\n        X = X.to(device)\n        probs_log = init_model(X)\n        probs = torch.softmax(probs_log, dim=-1)\n        initial_train_probs.append(probs.cpu())","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:25:55.852047Z","iopub.execute_input":"2024-01-01T04:25:55.852368Z","iopub.status.idle":"2024-01-01T04:26:29.662273Z","shell.execute_reply.started":"2024-01-01T04:25:55.852342Z","shell.execute_reply":"2024-01-01T04:26:29.661264Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"initial_val_probs = []\nwith torch.no_grad():\n    for X, _ in val_dataloader:\n        X = X.to(device)\n        probs_log = init_model(X)\n        probs = torch.softmax(probs_log, dim=-1)\n        initial_val_probs.append(probs.cpu())","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:26:29.664137Z","iopub.execute_input":"2024-01-01T04:26:29.664577Z","iopub.status.idle":"2024-01-01T04:26:36.744988Z","shell.execute_reply.started":"2024-01-01T04:26:29.664544Z","shell.execute_reply":"2024-01-01T04:26:36.744177Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"initial_train_probs[0].argmax(1)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:31:51.461675Z","iopub.execute_input":"2024-01-01T04:31:51.462501Z","iopub.status.idle":"2024-01-01T04:31:51.472581Z","shell.execute_reply.started":"2024-01-01T04:31:51.462468Z","shell.execute_reply":"2024-01-01T04:31:51.471632Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"tensor([4, 0, 4,  ..., 1, 1, 1])"},"metadata":{}}]},{"cell_type":"code","source":"X, actions = next(iter(train_dataloader))","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:28:51.024026Z","iopub.execute_input":"2024-01-01T04:28:51.024398Z","iopub.status.idle":"2024-01-01T04:28:51.034948Z","shell.execute_reply.started":"2024-01-01T04:28:51.024370Z","shell.execute_reply":"2024-01-01T04:28:51.034127Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"actions[0] # 64x500","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_probs_log = model(X)\nnew_probs = torch.softmax(new_probs_log, dim=-1)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:28:58.409687Z","iopub.execute_input":"2024-01-01T04:28:58.410530Z","iopub.status.idle":"2024-01-01T04:28:58.469674Z","shell.execute_reply.started":"2024-01-01T04:28:58.410495Z","shell.execute_reply":"2024-01-01T04:28:58.468990Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"new_probs.argmax(1).shape","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:30:34.804006Z","iopub.execute_input":"2024-01-01T04:30:34.804391Z","iopub.status.idle":"2024-01-01T04:30:34.810924Z","shell.execute_reply.started":"2024-01-01T04:30:34.804362Z","shell.execute_reply":"2024-01-01T04:30:34.810028Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"torch.Size([32000])"},"metadata":{}}]},{"cell_type":"code","source":"# one batch size has 64 trajectories, each trajectory has 500 steps = 64*500 = 30000 , 30000x5\n# 30000x1 \n# ratios = 30000x1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ppo_train(model, Q_est, optimizer, old_probs_train, clip_range=0.2):\n    model.train()\n    size = len(train_dataloader.dataset)\n    #old_probs = initial_train_probs\n    \n    for i, (X, actions) in enumerate(train_dataloader):\n        # Forward pass\n        #old_probs_log = model(X)\n        #old_probs = torch.softmax(old_probs_log, dim=-1)\n        old_probs = old_probs_train[i].argmax(1).to(device)\n        \n        Q_values = np.array([])\n        for j in range(64):\n            idx = i * 64 + j\n            Q_values = np.append(Q_values, Q_est[idx][actions[j]])\n        Q_values = torch.tensor(Q_values.reshape(-1, 1))\n        \n        advantages = (Q_values - Q_values.mean()) / (Q_values.std() + 1e-10)\n        advantages = torch.tensor(advantages, dtype=torch.float32).to(device)\n\n        #optimizer.zero_grad()\n        new_probs_log = model(X)\n        new_probs = torch.softmax(new_probs_log, dim=-1).argmax(1)\n\n        ratios = new_probs / (old_probs + 1e-10)\n\n        surr1 = advantages * ratios\n        surr2 = advantages * torch.clamp(ratios, 1-clip_range, 1+clip_range)\n        surr_loss = -torch.min(surr1, surr2).mean()\n        \n        kl_div = torch.distributions.kl_divergence(\n            torch.distributions.Categorical(probs=old_probs),\n            torch.distributions.Categorical(probs=new_probs)\n        ).mean()\n\n        loss = surr_loss + 0.01 * kl_div\n\n        # Take gradient step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        #with torch.no_grad():\n        #    updated_probs_log = model(X)\n        #    updated_probs = torch.softmax(updated_probs_log, dim=-1)\n        old_probs_train[i] = new_probs\n        if i % 100 == 0:\n            loss, current = loss.item(), (i + 1) * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n    \n    return old_probs_train","metadata":{"id":"J-_FPxlqQksa","execution":{"iopub.status.busy":"2024-01-01T04:33:49.308859Z","iopub.execute_input":"2024-01-01T04:33:49.309756Z","iopub.status.idle":"2024-01-01T04:33:49.320752Z","shell.execute_reply.started":"2024-01-01T04:33:49.309720Z","shell.execute_reply":"2024-01-01T04:33:49.319749Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def ppo_test(model, Q_est, old_probs_val, clip_range=0.2, kl_coeff=0.01):\n    model.eval()\n    num_batches = len(val_dataloader)\n    val_loss = 0.0\n\n    with torch.no_grad():\n        for i, (X, actions) in enumerate(val_dataloader):\n            #old_probs_log = model(X)\n            #old_probs = torch.softmax(old_probs_log, dim=-1)\n            old_probs = old_probs_val[i].argmax(1).to(device)\n            \n            Q_values = np.array([])\n            if i != 10000//64:\n                for j in range(64):\n                    idx = i * 64 + j\n                    if idx >= 10000:\n                        break\n                    Q_values = np.append(Q_values, Q_est[idx][actions[j]])\n            else: # last batch\n                for j in range(16):\n                    idx = i * 64 + j\n                    if idx >= 10000:\n                        break\n                    Q_values = np.append(Q_values, Q_est[idx][actions[j]])\n            Q_values = torch.tensor(Q_values.reshape(-1, 1))\n            \n            advantages = (Q_values - Q_values.mean()) / (Q_values.std() + 1e-10)\n            advantages = torch.tensor(advantages, dtype=torch.float32).to(device)\n            \n            new_probs_log = model(X)\n            new_probs = torch.softmax(new_probs_log, dim=-1).argmax(1)\n            \n            ratios = new_probs / (old_probs + 1e-10)\n            surr1 = ratios * advantages\n            surr2 = torch.clamp(ratios, 1-clip_range, 1+clip_range) * advantages\n            surr_loss = -torch.min(surr1, surr2).mean()\n            \n            val_loss += surr_loss.item()\n            \n            old_probs_val[i] = new_probs\n            \n    val_loss /= num_batches\n    \n    print(f\"Val loss: {val_loss:>8f} \\n\")\n    return val_loss, old_probs_val","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:33:52.553476Z","iopub.execute_input":"2024-01-01T04:33:52.554193Z","iopub.status.idle":"2024-01-01T04:33:52.565044Z","shell.execute_reply.started":"2024-01-01T04:33:52.554157Z","shell.execute_reply":"2024-01-01T04:33:52.564125Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"cur_epoch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nnp.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\ncur_val_loss = np.inf\ncur_epoch = 1\ncur_state_dict = None\nold_probs1 = initial_train_probs\nold_probs2 = initial_val_probs\n\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    old_probs1 = [prob.detach() for prob in old_probs1]\n    old_probs1 = ppo_train(model, Q_est_train, optimizer, old_probs1)\n    val_loss, old_probs2 = ppo_test(model, Q_est_val, old_probs2)\n    if val_loss < cur_val_loss:\n        cur_val_loss = val_loss\n        cur_epoch = t + 1\n        cur_state_dict = model.module.state_dict()\n        torch.save({\n            'epoch': cur_epoch,\n            'model_state_dict': cur_state_dict,\n            }, 'transformer_model.pt')\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:33:57.823427Z","iopub.execute_input":"2024-01-01T04:33:57.824178Z","iopub.status.idle":"2024-01-01T04:33:58.066643Z","shell.execute_reply.started":"2024-01-01T04:33:57.824140Z","shell.execute_reply":"2024-01-01T04:33:58.065522Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Epoch 1\n-------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1109387131.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  advantages = torch.tensor(advantages, dtype=torch.float32).to(device)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[39], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m old_probs1 \u001b[38;5;241m=\u001b[39m [prob\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mfor\u001b[39;00m prob \u001b[38;5;129;01min\u001b[39;00m old_probs1]\n\u001b[0;32m---> 12\u001b[0m old_probs1 \u001b[38;5;241m=\u001b[39m \u001b[43mppo_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ_est_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_probs1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m val_loss, old_probs2 \u001b[38;5;241m=\u001b[39m ppo_test(model, Q_est_val, old_probs2)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_loss \u001b[38;5;241m<\u001b[39m cur_val_loss:\n","Cell \u001b[0;32mIn[36], line 29\u001b[0m, in \u001b[0;36mppo_train\u001b[0;34m(model, Q_est, optimizer, old_probs_train, clip_range)\u001b[0m\n\u001b[1;32m     27\u001b[0m surr1 \u001b[38;5;241m=\u001b[39m advantages \u001b[38;5;241m*\u001b[39m ratios\n\u001b[1;32m     28\u001b[0m surr2 \u001b[38;5;241m=\u001b[39m advantages \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(ratios, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mclip_range, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mclip_range)\n\u001b[0;32m---> 29\u001b[0m surr_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msurr1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msurr2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     31\u001b[0m kl_div \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mkl_divergence(\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mCategorical(probs\u001b[38;5;241m=\u001b[39mold_probs),\n\u001b[1;32m     33\u001b[0m     torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mCategorical(probs\u001b[38;5;241m=\u001b[39mnew_probs)\n\u001b[1;32m     34\u001b[0m )\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     36\u001b[0m loss \u001b[38;5;241m=\u001b[39m surr_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.01\u001b[39m \u001b[38;5;241m*\u001b[39m kl_div\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.82 GiB (GPU 0; 14.76 GiB total capacity; 10.26 GiB already allocated; 3.69 GiB free; 10.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 3.82 GiB (GPU 0; 14.76 GiB total capacity; 10.26 GiB already allocated; 3.69 GiB free; 10.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"torch.save({\n            'model_state_dict': model.module.state_dict(),\n            }, 'transformer_model.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg = np.empty((500, n - 1))\n\nfor trial in range(500):\n    X, mu = generate()\n    X = torch.unsqueeze(torch.from_numpy(X).to(device), 0)\n    with torch.no_grad():\n        prediction = model.forward(X).cpu().numpy()\n    reg[trial] = np.max(mu) - mu[prediction.argmax(1)]","metadata":{"id":"2DOqEAPhOW0U","outputId":"7d0f58ec-a434-423a-9863-6e0e921629f7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_init = np.empty((500, n - 1))\n\nfor trial in range(500):\n    X, mu = generate()\n    X = torch.unsqueeze(torch.from_numpy(X).to(device), 0)\n    with torch.no_grad():\n        prediction = init_model.forward(X).cpu().numpy()\n    reg_init[trial] = np.max(mu) - mu[prediction.argmax(1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(np.arange(n - 1), reg_init.mean(0));","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg","metadata":{"id":"DSGrhOuzOfZE","outputId":"5c51ef9b-982c-40fb-db6a-57abb1b2d405","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(np.arange(n - 1), reg.mean(0));","metadata":{"id":"5CMGaV3kOcRe","outputId":"a44e4ab6-39f5-4651-f3ee-dee54615f250","trusted":true},"execution_count":null,"outputs":[]}]}