{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7316488,"sourceType":"datasetVersion","datasetId":4105007}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"id":"dm0vUHFiEtxF","outputId":"40f08354-8b24-4491-83b9-c69690c0ae77","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import GPT2Model, GPT2Config\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt","metadata":{"id":"-wLjihQUEk1l","execution":{"iopub.status.busy":"2024-01-03T05:57:06.407369Z","iopub.execute_input":"2024-01-03T05:57:06.408080Z","iopub.status.idle":"2024-01-03T05:57:11.431488Z","shell.execute_reply.started":"2024-01-03T05:57:06.408044Z","shell.execute_reply":"2024-01-03T05:57:11.430727Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"Zp6qkDfiF831","execution":{"iopub.status.busy":"2024-01-03T05:57:11.433270Z","iopub.execute_input":"2024-01-03T05:57:11.434003Z","iopub.status.idle":"2024-01-03T05:57:11.502553Z","shell.execute_reply.started":"2024-01-03T05:57:11.433970Z","shell.execute_reply":"2024-01-03T05:57:11.501500Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"A = 5 # number of actions\nN = 40000 # number of offline datasets\nn = 500 # context length\ntrials = 500 # online regret trials for val/test","metadata":{"id":"vaz-CdtzEr_4","execution":{"iopub.status.busy":"2024-01-03T05:57:11.503783Z","iopub.execute_input":"2024-01-03T05:57:11.504127Z","iopub.status.idle":"2024-01-03T05:57:11.515916Z","shell.execute_reply.started":"2024-01-03T05:57:11.504099Z","shell.execute_reply":"2024-01-03T05:57:11.514980Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def generate_B(A=5, N=40000, n=500):\n    dsets, actions = [], []\n    for i in tqdm(range(N)):\n        mu = np.random.rand(A)\n\n        p_1 = np.random.dirichlet(np.ones(A))\n        p_2 = np.zeros(A)\n        p_2[np.random.choice(A)] = 1\n        w = (np.random.choice(11)) / 10\n        p = (1 - w) * p_1 + w * p_2\n\n        a = np.random.choice(A, n, p=p)\n        actions.append(a)\n\n        r = np.random.normal(mu[a], 0.3)\n\n        X = np.zeros((n, A + 3), np.float32)\n        X[:, [0, -2]] = 1\n        X[np.arange(n), a + 1] = 1\n        X[:, -1] = r\n        dsets.append(X)\n    return dsets, actions","metadata":{"id":"3rbBQaMXE0vu","execution":{"iopub.status.busy":"2024-01-03T05:57:11.518187Z","iopub.execute_input":"2024-01-03T05:57:11.518480Z","iopub.status.idle":"2024-01-03T05:57:11.526706Z","shell.execute_reply.started":"2024-01-03T05:57:11.518455Z","shell.execute_reply":"2024-01-03T05:57:11.525862Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class BanditDataset(Dataset):\n    def __init__(self, dsets, actions):\n        self.dsets = dsets\n        self.actions = actions\n\n        self.first = np.zeros((1, A + 3), dtype=np.float32)\n        self.first[0, 0] = 1\n\n    def __len__(self):\n        return len(self.dsets)\n\n    def __getitem__(self, idx):\n        perm = np.random.permutation(n) # shuffled in-context datset to reduce overfitting\n        sample_ds = np.concatenate((self.first, self.dsets[idx][perm]))\n        return sample_ds, self.actions[idx][perm]","metadata":{"id":"KrkrrD4SE8p0","execution":{"iopub.status.busy":"2024-01-03T05:57:11.527902Z","iopub.execute_input":"2024-01-03T05:57:11.528290Z","iopub.status.idle":"2024-01-03T05:57:11.536552Z","shell.execute_reply.started":"2024-01-03T05:57:11.528255Z","shell.execute_reply":"2024-01-03T05:57:11.535599Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class TransformerModel(nn.Module):\n    def __init__(self, n_states, n_positions=501, n_embd=32, n_layer=4, n_head=4):\n        super(TransformerModel, self).__init__()\n        configuration = GPT2Config(\n            n_positions=n_positions,\n            n_embd=n_embd,\n            n_layer=n_layer,\n            n_head=n_head,\n        )\n        self.name = f\"gpt2_embd={n_embd}_layer={n_layer}_head={n_head}\"\n\n        self.n_positions = n_positions\n        self.n_dims = n_states\n        self._read_in = nn.Linear(n_states + 3, n_embd)\n        self._backbone = GPT2Model(configuration)\n        self._read_out = nn.Linear(n_embd, n_states)\n        self._flatten = nn.Flatten(0, 1)\n\n        for w in self._backbone.wpe.parameters(): # remove positional embedding\n            w.data.fill_(0)\n        self._backbone.wpe.weight.requires_grad=False\n\n    def forward(self, X):\n        embeds = self._read_in(X)\n        output = self._backbone(inputs_embeds=embeds).last_hidden_state\n        logit = self._read_out(output)[:, :-1]\n        logit = self._flatten(logit)\n        return logit","metadata":{"id":"wD1smOF4E_5n","execution":{"iopub.status.busy":"2024-01-03T05:57:11.537823Z","iopub.execute_input":"2024-01-03T05:57:11.538619Z","iopub.status.idle":"2024-01-03T05:57:11.548108Z","shell.execute_reply.started":"2024-01-03T05:57:11.538582Z","shell.execute_reply":"2024-01-03T05:57:11.547220Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dsets_train, actions_train = generate_B(N=N)\ndsets_val, actions_val = generate_B(N=N//4)\n\ndata_train = BanditDataset(dsets_train, actions_train)\ndata_val = BanditDataset(dsets_val, actions_val)\n\ntrain_dataloader = DataLoader(data_train, batch_size=64)\nval_dataloader = DataLoader(data_val, batch_size=64)","metadata":{"id":"JaOb-DhyFHJZ","outputId":"d10e0350-9d69-445e-b54b-1c9e889110ea","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(dsets_train, 'dsets_train.pth')\ntorch.save(dsets_val, 'dsets_val.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(actions_train, 'actions_train.pth')\ntorch.save(actions_val, 'actions_val.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dsets_train = torch.load('/kaggle/input/bandit-data1/dsets_train.pth')\ndsets_val = torch.load('/kaggle/input/bandit-data1/dsets_val.pth')","metadata":{"execution":{"iopub.status.busy":"2024-01-03T05:57:11.549502Z","iopub.execute_input":"2024-01-03T05:57:11.549899Z","iopub.status.idle":"2024-01-03T05:57:21.302114Z","shell.execute_reply.started":"2024-01-03T05:57:11.549849Z","shell.execute_reply":"2024-01-03T05:57:21.301330Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"actions_train = torch.load('/kaggle/input/bandit-data1/actions_train.pth')\nactions_val = torch.load('/kaggle/input/bandit-data1/actions_val.pth')","metadata":{"execution":{"iopub.status.busy":"2024-01-03T05:57:21.304917Z","iopub.execute_input":"2024-01-03T05:57:21.305202Z","iopub.status.idle":"2024-01-03T05:57:23.086594Z","shell.execute_reply.started":"2024-01-03T05:57:21.305171Z","shell.execute_reply":"2024-01-03T05:57:23.085813Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data_train = BanditDataset(dsets_train, actions_train)\ndata_val = BanditDataset(dsets_val, actions_val)\n\ntrain_dataloader = DataLoader(data_train, batch_size=64)\nval_dataloader = DataLoader(data_val, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T05:57:23.091186Z","iopub.execute_input":"2024-01-03T05:57:23.091777Z","iopub.status.idle":"2024-01-03T05:57:23.097526Z","shell.execute_reply.started":"2024-01-03T05:57:23.091743Z","shell.execute_reply":"2024-01-03T05:57:23.096626Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = TransformerModel(n_states=A)\nmodel.to(device)\nmodel = nn.DataParallel(model)\noptimizer = torch.optim.AdamW([param for param in model.parameters() if param.requires_grad == True])","metadata":{"id":"auCE_VMpFkl5","execution":{"iopub.status.busy":"2024-01-03T06:38:52.732197Z","iopub.execute_input":"2024-01-03T06:38:52.732967Z","iopub.status.idle":"2024-01-03T06:38:52.775626Z","shell.execute_reply.started":"2024-01-03T06:38:52.732935Z","shell.execute_reply":"2024-01-03T06:38:52.774861Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"Train Initial Policy","metadata":{"id":"vO7Chq67BfOo"}},{"cell_type":"code","source":"def train_initial_policy(model, data_loader, optimizer):\n    size = len(data_loader.dataset)\n    model.train()\n    for batch, (X, a) in enumerate(train_dataloader):\n        X = X.to(device)\n        pred = model(X)\n        a = a.flatten().to(device)\n\n        loss_fn = torch.nn.CrossEntropyLoss()\n        loss = torch.mean(loss_fn(pred, a))\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), (batch + 1) * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")","metadata":{"id":"i2CloUmT7JLZ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_initial_policy(model, dataloader):\n    num_batches = len(dataloader)\n    model.eval()\n    val_loss = 0\n\n    with torch.no_grad():\n        for X, a in dataloader:\n            X = X.to(device)\n            pred = model(X)\n            a = a.flatten().to(device)\n\n            loss_fn = torch.nn.CrossEntropyLoss()\n            loss = torch.mean(loss_fn(pred, a))\n            val_loss += loss.item()\n\n    val_loss /= num_batches\n    print(f\"Val loss: {val_loss:>8f} \\n\")\n    return val_loss","metadata":{"id":"sTSAVwU2Pa9q","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nnp.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\ncur_val_loss = np.inf\ncur_epoch = 1\ncur_state_dict = None\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train_initial_policy(model, train_dataloader, optimizer)\n    if test_initial_policy(model, val_dataloader) < cur_val_loss:\n        cur_epoch = t + 1\n        cur_state_dict = model.module.state_dict()\n        torch.save({\n            'epoch': cur_epoch,\n            'model_state_dict': cur_state_dict,\n            }, 'transformer_model.pt')\nprint(\"Done!\")","metadata":{"id":"C-gE2Re-Po9m","outputId":"32e70cfe-13f9-49ba-9246-4cff33438c66","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'initial_policy.pth')","metadata":{"id":"brGHYYCKovX4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/input/bandit-data1/initial_policy.pth'))\nmodel.to(device)","metadata":{"id":"YYaEXmHU41aI","outputId":"6c72164d-1028-40fb-902c-835f57cb094f","execution":{"iopub.status.busy":"2024-01-03T07:03:40.589389Z","iopub.execute_input":"2024-01-03T07:03:40.589783Z","iopub.status.idle":"2024-01-03T07:03:40.618441Z","shell.execute_reply.started":"2024-01-03T07:03:40.589751Z","shell.execute_reply":"2024-01-03T07:03:40.617539Z"},"trusted":true},"execution_count":91,"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): TransformerModel(\n    (_read_in): Linear(in_features=8, out_features=32, bias=True)\n    (_backbone): GPT2Model(\n      (wte): Embedding(50257, 32)\n      (wpe): Embedding(501, 32)\n      (drop): Dropout(p=0.1, inplace=False)\n      (h): ModuleList(\n        (0-3): 4 x GPT2Block(\n          (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n          (attn): GPT2Attention(\n            (c_attn): Conv1D()\n            (c_proj): Conv1D()\n            (attn_dropout): Dropout(p=0.1, inplace=False)\n            (resid_dropout): Dropout(p=0.1, inplace=False)\n          )\n          (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n          (mlp): GPT2MLP(\n            (c_fc): Conv1D()\n            (c_proj): Conv1D()\n            (act): NewGELUActivation()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (ln_f): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n    )\n    (_read_out): Linear(in_features=32, out_features=5, bias=True)\n    (_flatten): Flatten(start_dim=0, end_dim=1)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def generate(A=5, N=1, n=500):\n    mu = np.random.rand(A)\n\n    p_1 = np.random.dirichlet(np.ones(A))\n    p_2 = np.zeros(A)\n    p_2[np.random.choice(A)] = 1\n    w = (np.random.choice(11)) / 10\n    p = (1 - w) * p_1 + w * p_2\n\n    a = np.random.choice(A, n, p=p)\n\n    r = np.random.normal(mu[a], 0.3)\n\n    X = np.zeros((n, A + 3), np.float32)\n    X[:, [0, -2]] = 1\n    X[np.arange(n), a + 1] = 1\n    X[:, -1] = r\n    return X, mu","metadata":{"id":"2ZoZulnOvlzA","execution":{"iopub.status.busy":"2024-01-03T05:57:25.994413Z","iopub.execute_input":"2024-01-03T05:57:25.994703Z","iopub.status.idle":"2024-01-03T05:57:26.001874Z","shell.execute_reply.started":"2024-01-03T05:57:25.994661Z","shell.execute_reply":"2024-01-03T05:57:26.000959Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"reg = np.empty((500, n - 1))\n\nfor trial in range(500):\n    X, mu = generate()\n    X = torch.unsqueeze(torch.from_numpy(X).to(device), 0)\n    with torch.no_grad():\n        prediction = model.forward(X).cpu().numpy()\n    reg[trial] = np.max(mu) - mu[prediction.argmax(1)]","metadata":{"id":"XVDQSafH1alD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, mu = generate()\nX = torch.unsqueeze(torch.from_numpy(X).to(device), 0)\nwith torch.no_grad():\n    prediction = model.forward(X).cpu().numpy()","metadata":{"id":"zJ_yxN8zbsY-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Q function: Q(a) = E(Rt|At=a)","metadata":{"id":"zaNP1SCqBhZt"}},{"cell_type":"code","source":"def select_action_with_policy(model, X):\n    X = torch.unsqueeze(torch.from_numpy(X).to(device), 0)\n    with torch.no_grad():\n        predictions = model.forward(X).cpu().numpy()\n    return predictions","metadata":{"id":"9IoY03kHBjVA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Q_function(dsets, actions, N=N):\n    Q_est = np.zeros((N, A))\n\n    for trial in tqdm(range(N)):\n        Qa = np.zeros(A)\n        Na = np.zeros(A)\n\n        X = dsets[trial]\n        a = actions[trial]\n\n        for i in range(n):\n            reward = X[i, -1]\n            action = a[i]\n\n            Na[action] += 1\n            Qa[action] += reward\n        \n        Q_est[trial] = np.nan_to_num(Qa / Na)\n\n    return Q_est","metadata":{"id":"be7zRscqk8Kn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Q_est_train = e_greedy_k_armed_bandit_with_policy(model, dsets_train)\n# Q_est_val = e_greedy_k_armed_bandit_with_policy(model, dsets_val, N=N//4)\n\nQ_est_train = Q_function(dsets_train, actions_train)\nQ_est_val = Q_function(dsets_val, actions_val, N=N//4)","metadata":{"id":"ZmuGaJ3Nk80x","outputId":"15ec3d67-718a-461e-e0b4-36cff658473e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(Q_est_train, 'Q_est_train.pth')\ntorch.save(Q_est_val, 'Q_est_val.pth')","metadata":{"id":"eh7BHFrC05Ag"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Q_est_train = torch.load('/kaggle/input/bandit-data1/Q_est_train-2.pth')\nQ_est_val = torch.load('/kaggle/input/bandit-data1/Q_est_val-2.pth')","metadata":{"execution":{"iopub.status.busy":"2024-01-03T05:57:26.003040Z","iopub.execute_input":"2024-01-03T05:57:26.003388Z","iopub.status.idle":"2024-01-03T05:57:26.055189Z","shell.execute_reply.started":"2024-01-03T05:57:26.003355Z","shell.execute_reply":"2024-01-03T05:57:26.054249Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Policy Improvement","metadata":{"id":"v2G_BYkWQiJ9"}},{"cell_type":"code","source":"init_model = TransformerModel(n_states=A)\ninit_model.to(device)\ninit_model = nn.DataParallel(init_model)\ninit_model.load_state_dict(torch.load('/kaggle/input/bandit-data1/initial_policy.pth'))\ninit_model.eval()","metadata":{"execution":{"iopub.status.busy":"2024-01-03T07:03:51.284961Z","iopub.execute_input":"2024-01-03T07:03:51.285416Z","iopub.status.idle":"2024-01-03T07:03:51.376207Z","shell.execute_reply.started":"2024-01-03T07:03:51.285381Z","shell.execute_reply":"2024-01-03T07:03:51.375150Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): TransformerModel(\n    (_read_in): Linear(in_features=8, out_features=32, bias=True)\n    (_backbone): GPT2Model(\n      (wte): Embedding(50257, 32)\n      (wpe): Embedding(501, 32)\n      (drop): Dropout(p=0.1, inplace=False)\n      (h): ModuleList(\n        (0-3): 4 x GPT2Block(\n          (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n          (attn): GPT2Attention(\n            (c_attn): Conv1D()\n            (c_proj): Conv1D()\n            (attn_dropout): Dropout(p=0.1, inplace=False)\n            (resid_dropout): Dropout(p=0.1, inplace=False)\n          )\n          (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n          (mlp): GPT2MLP(\n            (c_fc): Conv1D()\n            (c_proj): Conv1D()\n            (act): NewGELUActivation()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (ln_f): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n    )\n    (_read_out): Linear(in_features=32, out_features=5, bias=True)\n    (_flatten): Flatten(start_dim=0, end_dim=1)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"initial_train_probs = []\nfor X, _ in train_dataloader:\n    X = X.to(device)\n    probs_log = init_model(X)\n    probs = torch.softmax(probs_log, dim=-1)\n    initial_train_probs.append(probs.detach())","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:26:52.432842Z","iopub.execute_input":"2024-01-03T06:26:52.433165Z","iopub.status.idle":"2024-01-03T06:27:16.016625Z","shell.execute_reply.started":"2024-01-03T06:26:52.433139Z","shell.execute_reply":"2024-01-03T06:27:16.015831Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"initial_val_probs = []\nfor X, _ in val_dataloader:\n    X = X.to(device)\n    probs_log = init_model(X)\n    probs = torch.softmax(probs_log, dim=-1)\n    initial_val_probs.append(probs.detach())","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:28:22.962638Z","iopub.execute_input":"2024-01-03T06:28:22.963543Z","iopub.status.idle":"2024-01-03T06:28:28.848719Z","shell.execute_reply.started":"2024-01-03T06:28:22.963485Z","shell.execute_reply":"2024-01-03T06:28:28.847895Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"torch.save(initial_train_probs, 'initial_train_probs.pth')\ntorch.save(initial_val_probs, 'initial_val_probs.pth')","metadata":{"execution":{"iopub.status.busy":"2024-01-03T06:28:35.342510Z","iopub.execute_input":"2024-01-03T06:28:35.342839Z","iopub.status.idle":"2024-01-03T06:28:36.059260Z","shell.execute_reply.started":"2024-01-03T06:28:35.342813Z","shell.execute_reply":"2024-01-03T06:28:36.058220Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"initial_train_probs = torch.load('/kaggle/working/initial_train_probs.pth')\ninitial_val_probs = torch.load('/kaggle/working/initial_val_probs.pth')","metadata":{"execution":{"iopub.status.busy":"2024-01-03T07:03:54.010927Z","iopub.execute_input":"2024-01-03T07:03:54.011297Z","iopub.status.idle":"2024-01-03T07:03:54.474209Z","shell.execute_reply.started":"2024-01-03T07:03:54.011270Z","shell.execute_reply":"2024-01-03T07:03:54.473422Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"# one batch size has 64 trajectories, each trajectory has 500 steps = 64*500 = 30000 , 30000x5\n# 30000x1 \n# ratios = 30000x1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ppo_train(model, optimizer, old_probs_train, clip_range=0.2):\n    model.train()\n    size = len(train_dataloader.dataset)\n    next_probs = old_probs_train.copy()\n    \n    for i, (X, actions) in enumerate(train_dataloader):\n        # Forward pass\n        #old_probs_log = model(X)\n        #old_probs = torch.softmax(old_probs_log, dim=-1)\n        old_probs = old_probs_train[i].to(device)\n        X = X.to(device)\n        actions_flat = actions.view((-1, 1)).to(device)\n\n        Q_values = np.array([])\n        for j in range(64):\n            idx = i * 64 + j\n            Q_values = np.append(Q_values, Q_est_train[idx][actions[j]])\n        Q_values = torch.tensor(Q_values.reshape(-1, 1))\n        \n        advantages = ((Q_values - Q_values.mean()) / (Q_values.std() + 1e-10)).to(device)\n        \n        #optimizer.zero_grad()\n        new_probs_log = model(X)\n        new_probs = torch.softmax(new_probs_log, dim=-1)\n        \n        old_chosen_probs = old_probs.gather(1, actions_flat).squeeze()\n        new_chosen_probs = new_probs.gather(1, actions_flat).squeeze()\n\n        ratios = (new_probs - old_probs).exp() #new_probs / (old_probs + 1e-10)\n\n        surr1 = advantages * ratios\n        surr2 = advantages * torch.clamp(ratios, 1-clip_range, 1+clip_range)\n        surr_loss = -torch.min(surr1, surr2).mean()\n        \n        kl_div = torch.distributions.kl_divergence(\n            torch.distributions.Categorical(probs=old_probs),\n            torch.distributions.Categorical(probs=new_probs)\n        ).mean()\n        \n        loss = surr_loss + 0.01 * kl_div\n\n        # Take gradient step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        #with torch.no_grad():\n        #    updated_probs_log = model(X)\n        #    updated_probs = torch.softmax(updated_probs_log, dim=-1)\n        next_probs[i] = new_probs_log\n        if i % 100 == 0:\n            loss, current = loss.item(), (i + 1) * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n    \n    return next_probs","metadata":{"id":"J-_FPxlqQksa","execution":{"iopub.status.busy":"2024-01-03T07:03:58.407054Z","iopub.execute_input":"2024-01-03T07:03:58.407420Z","iopub.status.idle":"2024-01-03T07:03:58.419569Z","shell.execute_reply.started":"2024-01-03T07:03:58.407388Z","shell.execute_reply":"2024-01-03T07:03:58.418652Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"def ppo_test(model, old_probs_val, clip_range=0.2, kl_coeff=0.01):\n    model.eval()\n    num_batches = len(val_dataloader)\n    val_loss = 0.0\n    next_probs = old_probs_val.copy()\n\n    with torch.no_grad():\n        for i, (X, actions) in enumerate(val_dataloader):\n            #old_probs_log = model(X)\n            #old_probs = torch.softmax(old_probs_log, dim=-1)\n            X = X.to(device)\n            old_probs = old_probs_val[i].to(device)\n            actions_flat = actions.view((-1, 1)).to(device)\n            \n            Q_values = np.array([])\n            if i != 10000//64:\n                for j in range(64):\n                    idx = i * 64 + j\n                    if idx >= 10000:\n                        break\n                    Q_values = np.append(Q_values, Q_est_val[idx][actions[j]])\n            else: # last batch\n                for j in range(16):\n                    idx = i * 64 + j\n                    if idx >= 10000:\n                        break\n                    Q_values = np.append(Q_values, Q_est_val[idx][actions[j]])\n            Q_values = torch.tensor(Q_values.reshape(-1, 1))\n            \n            advantages = ((Q_values - Q_values.mean()) / (Q_values.std() + 1e-10)).to(device)\n            \n            new_probs_log = model(X)\n            new_probs = torch.softmax(new_probs_log, dim=-1)\n            \n            old_chosen_probs = old_probs.gather(1, actions_flat).squeeze()\n            new_chosen_probs = new_probs.gather(1, actions_flat).squeeze()\n            \n            ratios = (new_probs - old_probs).exp()\n            \n            surr1 = advantages * ratios\n            surr2 = advantages * torch.clamp(ratios, 1-clip_range, 1+clip_range)\n            surr_loss = -torch.min(surr1, surr2).mean()\n            \n            val_loss += surr_loss.item()\n            \n            next_probs[i] = new_probs\n            \n    val_loss /= num_batches\n    \n    print(f\"Val loss: {val_loss:>8f} \\n\")\n    return val_loss, next_probs","metadata":{"execution":{"iopub.status.busy":"2024-01-03T07:03:59.017059Z","iopub.execute_input":"2024-01-03T07:03:59.017419Z","iopub.status.idle":"2024-01-03T07:03:59.030347Z","shell.execute_reply.started":"2024-01-03T07:03:59.017390Z","shell.execute_reply":"2024-01-03T07:03:59.029397Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"epochs = 50\nnp.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\ncur_val_loss = np.inf\ncur_epoch = 1\ncur_state_dict = None\nold_probs1 = initial_train_probs\nold_probs2 = initial_val_probs\n\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    #old_probs1 = [prob.clone().detach() for prob in old_probs1]\n    old_probs1 = ppo_train(model, optimizer, old_probs1)\n    val_loss, old_probs2 = ppo_test(model, old_probs2)\n    if val_loss < cur_val_loss:\n        cur_val_loss = val_loss\n        cur_epoch = t + 1\n        cur_state_dict = model.module.state_dict()\n        torch.save({\n            'epoch': cur_epoch,\n            'model_state_dict': cur_state_dict,\n            }, 'transformer_model.pt')\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2024-01-03T07:03:59.868999Z","iopub.execute_input":"2024-01-03T07:03:59.869330Z","iopub.status.idle":"2024-01-03T07:05:08.102101Z","shell.execute_reply.started":"2024-01-03T07:03:59.869307Z","shell.execute_reply":"2024-01-03T07:05:08.100819Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"Epoch 1\n-------------------------------\nloss: 0.000433  [   64/40000]\nloss: 0.000369  [ 6464/40000]\nloss: 0.000300  [12864/40000]\nloss: 0.000298  [19264/40000]\nloss: 0.000555  [25664/40000]\nloss: -0.003761  [32064/40000]\nloss: -0.005659  [38464/40000]\nVal loss: -0.006855 \n\nEpoch 2\n-------------------------------\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[96], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#old_probs1 = [prob.clone().detach() for prob in old_probs1]\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m old_probs1 \u001b[38;5;241m=\u001b[39m \u001b[43mppo_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_probs1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m val_loss, old_probs2 \u001b[38;5;241m=\u001b[39m ppo_test(model, old_probs2)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_loss \u001b[38;5;241m<\u001b[39m cur_val_loss:\n","Cell \u001b[0;32mIn[94], line 36\u001b[0m, in \u001b[0;36mppo_train\u001b[0;34m(model, optimizer, old_probs_train, clip_range)\u001b[0m\n\u001b[1;32m     32\u001b[0m surr2 \u001b[38;5;241m=\u001b[39m advantages \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(ratios, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mclip_range, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mclip_range)\n\u001b[1;32m     33\u001b[0m surr_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmin(surr1, surr2)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     35\u001b[0m kl_div \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mkl_divergence(\n\u001b[0;32m---> 36\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mold_probs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     37\u001b[0m     torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mCategorical(probs\u001b[38;5;241m=\u001b[39mnew_probs)\n\u001b[1;32m     38\u001b[0m )\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     40\u001b[0m loss \u001b[38;5;241m=\u001b[39m surr_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.01\u001b[39m \u001b[38;5;241m*\u001b[39m kl_div\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Take gradient step\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/distributions/categorical.py:66\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     65\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mSize()\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/distributions/distribution.py:62\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     60\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m---> 62\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     63\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m             )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n","\u001b[0;31mValueError\u001b[0m: Expected parameter probs (Tensor of shape (32000, 5)) of distribution Categorical(probs: torch.Size([32000, 5])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([[ 0.1875, -0.0367,  0.4879,  0.1013,  0.2600],\n        [ 0.0306, -0.0242,  0.1482, -0.0205,  0.8659],\n        [-0.1003, -0.0180,  0.1054, -0.0442,  1.0571],\n        ...,\n        [ 0.2519, -1.7525,  0.2629,  0.9167,  1.3211],\n        [ 0.3159, -2.8477,  0.2843,  1.3181,  1.9293],\n        [ 0.2251, -2.5139,  0.3007,  1.2921,  1.6960]], device='cuda:0',\n       grad_fn=<DivBackward0>)"],"ename":"ValueError","evalue":"Expected parameter probs (Tensor of shape (32000, 5)) of distribution Categorical(probs: torch.Size([32000, 5])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([[ 0.1875, -0.0367,  0.4879,  0.1013,  0.2600],\n        [ 0.0306, -0.0242,  0.1482, -0.0205,  0.8659],\n        [-0.1003, -0.0180,  0.1054, -0.0442,  1.0571],\n        ...,\n        [ 0.2519, -1.7525,  0.2629,  0.9167,  1.3211],\n        [ 0.3159, -2.8477,  0.2843,  1.3181,  1.9293],\n        [ 0.2251, -2.5139,  0.3007,  1.2921,  1.6960]], device='cuda:0',\n       grad_fn=<DivBackward0>)","output_type":"error"}]},{"cell_type":"code","source":"torch.save({\n            'model_state_dict': model.module.state_dict(),\n            }, 'transformer_model.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg = np.empty((500, n - 1))\n\nfor trial in range(500):\n    X, mu = generate()\n    X = torch.unsqueeze(torch.from_numpy(X).to(device), 0)\n    with torch.no_grad():\n        prediction = model.forward(X).cpu().numpy()\n    reg[trial] = np.max(mu) - mu[prediction.argmax(1)]","metadata":{"id":"2DOqEAPhOW0U","outputId":"7d0f58ec-a434-423a-9863-6e0e921629f7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_init = np.empty((500, n - 1))\n\nfor trial in range(500):\n    X, mu = generate()\n    X = torch.unsqueeze(torch.from_numpy(X).to(device), 0)\n    with torch.no_grad():\n        prediction = init_model.forward(X).cpu().numpy()\n    reg_init[trial] = np.max(mu) - mu[prediction.argmax(1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(np.arange(n - 1), reg_init.mean(0));","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg","metadata":{"id":"DSGrhOuzOfZE","outputId":"5c51ef9b-982c-40fb-db6a-57abb1b2d405","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(np.arange(n - 1), reg.mean(0));","metadata":{"id":"5CMGaV3kOcRe","outputId":"a44e4ab6-39f5-4651-f3ee-dee54615f250","trusted":true},"execution_count":null,"outputs":[]}]}