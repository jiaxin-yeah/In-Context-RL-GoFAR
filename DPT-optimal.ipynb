{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce21e60-73f2-421d-b8d5-c8a7023b20a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Model, GPT2Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bdba263-b726-4316-80b5-2be5e2fb6c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d945d95-155d-4bed-b879-5af6f0d32f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 5 # number of actions\n",
    "N = 80000 # number of offline samples\n",
    "n = 500\n",
    "eps = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae1187e-a08c-4632-b28a-341cba54f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_B(A=5, N=80000, n=500):\n",
    "    dsets, max_idx, means, ps = [], [], [], []\n",
    "    for i in range(N):\n",
    "        p_1 = np.random.dirichlet(np.ones(A))\n",
    "        p_2 = np.zeros(A)\n",
    "        idx = np.random.choice(A)\n",
    "        p_2[idx] = 1\n",
    "        w = (np.random.choice(10) + 1) / 10\n",
    "        p = (1 - w) * p_1 + w * p_2\n",
    "        ps.append(p)\n",
    "        \n",
    "        a = np.random.choice(A, n, p=p)\n",
    "        mu = np.random.rand(A)\n",
    "        means.append(mu)\n",
    "        max_idx.append(np.argmax(mu))\n",
    "        r = np.random.normal(mu[a], 0.3)\n",
    "        \n",
    "        a_one_hot = np.zeros((n, A))\n",
    "        a_one_hot[np.arange(n), a] = 1\n",
    "\n",
    "        X = np.zeros((n, A + 3), np.float32)\n",
    "        X[:, 0] = 1\n",
    "        X[:, 1:A + 1] = a_one_hot\n",
    "        X[:, -2] = 1\n",
    "        X[:, -1] = r\n",
    "        dsets.append(X)\n",
    "    return dsets, max_idx, means, ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35da59b2-a19c-49d2-9569-7094673a64c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditDataset(Dataset):\n",
    "    def __init__(self, dsets, max_idx, means, ps):\n",
    "        self.dsets = dsets\n",
    "        self.max_idx = max_idx\n",
    "        self.means = means\n",
    "        self.ps = ps\n",
    "        \n",
    "        self.first = np.zeros((1, A + 3), dtype=np.float32)\n",
    "        self.first[0, 0] = 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dsets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_ds = self.dsets[idx]\n",
    "        np.random.shuffle(sample_ds)\n",
    "        sample_ds = torch.from_numpy(np.concatenate((self.first, sample_ds)))\n",
    "        sample_max_idx = self.max_idx[idx]\n",
    "        sample_means = self.means[idx]\n",
    "        sample_ps = self.ps[idx]\n",
    "        \n",
    "        return sample_ds, sample_max_idx, sample_means, sample_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de84ccd0-4156-4f20-9b53-1fc8be5f7ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, n_states, n_positions=501, n_embd=32, n_layer=4, n_head=4):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        configuration = GPT2Config(\n",
    "            n_positions=n_positions,\n",
    "            n_embd=n_embd,\n",
    "            n_layer=n_layer,\n",
    "            n_head=n_head,\n",
    "        )\n",
    "        self.name = f\"gpt2_embd={n_embd}_layer={n_layer}_head={n_head}\"\n",
    "\n",
    "        self.n_positions = n_positions\n",
    "        self.n_dims = n_states\n",
    "        self._read_in = nn.Linear(n_states + 3, n_embd)\n",
    "        self._backbone = GPT2Model(configuration)\n",
    "        self._read_out = nn.Linear(n_embd, 5)\n",
    "        self._flatten = nn.Flatten(0, 1)\n",
    "\n",
    "        for w in self._backbone.wpe.parameters():\n",
    "            w.data.fill_(0)\n",
    "        self._backbone.wpe.weight.requires_grad=False\n",
    "\n",
    "    def forward(self, X):\n",
    "        embeds = self._read_in(X)\n",
    "        output = self._backbone(inputs_embeds=embeds).last_hidden_state\n",
    "        logit = self._read_out(output)[:, 1:]\n",
    "        logit = self._flatten(logit)\n",
    "\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc8289d6-2481-4a96-8ef6-7255d573d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, max_idx, mu, p) in enumerate(train_dataloader):\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "    \n",
    "        max_idx = max_idx.repeat_interleave(500).to(device)\n",
    "        loss = loss_fn(pred, max_idx)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7873169-e185-4254-9248-99591294a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    ds = []\n",
    "    with torch.no_grad():\n",
    "        for X, max_idx, mu, p in dataloader:\n",
    "            X = X.to(device)\n",
    "            pred = model(X)\n",
    "        \n",
    "            max_idx = max_idx.repeat_interleave(500).to(device)\n",
    "            loss = loss_fn(pred, max_idx)\n",
    "\n",
    "            mu = mu.to(device)\n",
    "            d = torch.dot(torch.softmax(pred[-1], 0), mu[-1].float())\n",
    "            if d < torch.max(mu[-1]) - 0.1 and torch.max(p[-1]) < 1:\n",
    "                print(mu[-1].cpu().detach().numpy(), torch.softmax(pred[-1], 0).cpu().detach().numpy(), p[-1].cpu().detach().numpy())\n",
    "            ds.append(torch.max(mu[-1]).item() - d.item())\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= num_batches\n",
    "    print(np.array(ds).mean())\n",
    "    print(f\"Val loss: {val_loss:>8f} \\n\")\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e78b230b-d8ea-42d0-bc78-6e602f9eebf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = TransformerModel(n_states=5)\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b986afb5-bda9-48e8-b386-29aee23c99b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW([param for param in model.parameters() if param.requires_grad == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0e4c60a-d79c-40ba-85e5-a733a4a36a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets_train, max_idx_train, means_train, ps_train = generate_B(N=N)\n",
    "dsets_val, max_idx_val, means_val, ps_val = generate_B(N=N//4)\n",
    "\n",
    "train_data = BanditDataset(dsets_train, max_idx_train, means_train, ps_train)\n",
    "val_data = BanditDataset(dsets_val, max_idx_val, means_val, ps_val)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "val_dataloader = DataLoader(val_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66afb45-3fd8-4943-a06b-ef06f7268fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.736755  [   64/80000]\n",
      "loss: 1.611459  [ 6464/80000]\n",
      "loss: 1.049074  [12864/80000]\n",
      "loss: 1.057561  [19264/80000]\n",
      "loss: 0.841092  [25664/80000]\n",
      "loss: 0.845541  [32064/80000]\n",
      "loss: 1.081182  [38464/80000]\n",
      "loss: 0.785529  [44864/80000]\n",
      "loss: 0.854464  [51264/80000]\n",
      "loss: 0.775369  [57664/80000]\n",
      "loss: 0.768404  [64064/80000]\n",
      "loss: 0.838525  [70464/80000]\n",
      "loss: 0.957628  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.162 0.093 0.247 0.009 0.490] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.008 0.004 0.206 0.076 0.707] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.358 0.009 0.053 0.491 0.089] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.687 0.841 0.667 0.277 0.485] [0.083 0.349 0.469 0.001 0.098] [0.654 0.172 0.075 0.039 0.059]\n",
      "[0.613 0.941 0.801 0.746 0.456] [0.257 0.608 0.096 0.037 0.003] [0.033 0.007 0.196 0.023 0.742]\n",
      "[0.932 0.728 0.064 0.537 0.281] [0.798 0.036 0.001 0.028 0.138] [0.141 0.057 0.363 0.433 0.006]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.214 0.161 0.001 0.165 0.458] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.027 0.179 0.623 0.774 0.205] [0.088 0.006 0.211 0.452 0.244] [0.002 0.047 0.922 0.022 0.007]\n",
      "[0.113 0.227 0.741 0.213 0.899] [0.064 0.002 0.300 0.008 0.626] [0.010 0.843 0.049 0.007 0.092]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.478 0.002 0.101 0.019 0.401] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.646 0.050 0.146 0.007 0.151] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.213 0.805 0.964 0.316 0.763] [0.260 0.100 0.526 0.005 0.110] [0.002 0.082 0.032 0.048 0.836]\n",
      "[0.318 0.323 0.742 0.726 0.087] [0.225 0.006 0.637 0.130 0.002] [0.004 0.069 0.502 0.127 0.298]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.141 0.014 0.046 0.517 0.282] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.730 0.996 0.188 0.880 0.120] [0.107 0.179 0.003 0.707 0.004] [0.031 0.011 0.034 0.079 0.846]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.316 0.025 0.116 0.445 0.098] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.169 0.702 0.758 0.978 0.311] [0.007 0.223 0.275 0.492 0.003] [0.088 0.092 0.222 0.039 0.559]\n",
      "[0.087 0.322 0.462 0.836 0.699] [0.020 0.153 0.008 0.752 0.068] [0.007 0.002 0.053 0.099 0.839]\n",
      "[0.791 0.232 0.706 0.933 0.349] [0.544 0.001 0.067 0.361 0.027] [0.028 0.902 0.015 0.019 0.037]\n",
      "[0.848 0.839 0.660 0.531 0.680] [0.048 0.212 0.002 0.003 0.735] [0.237 0.191 0.443 0.122 0.006]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.148 0.179 0.083 0.537 0.053] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.930 0.269 0.275 0.510 0.614] [0.766 0.023 0.013 0.164 0.034] [0.130 0.019 0.008 0.005 0.838]\n",
      "[0.269 0.191 0.731 0.853 0.971] [0.051 0.004 0.090 0.451 0.404] [0.011 0.139 0.007 0.812 0.031]\n",
      "[0.452 0.266 0.174 0.746 0.141] [0.493 0.008 0.010 0.483 0.006] [0.044 0.257 0.036 0.019 0.644]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.271 0.084 0.110 0.018 0.517] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.213 0.026 0.038 0.205 0.518] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.929 0.612 0.604 0.009 0.440] [0.611 0.040 0.286 0.001 0.063] [0.016 0.204 0.180 0.546 0.054]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.309 0.053 0.005 0.552 0.082] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.054 0.836 0.173 0.498 0.621] [0.002 0.370 0.002 0.029 0.596] [0.246 0.094 0.457 0.191 0.011]\n",
      "[0.280 0.619 0.705 0.573 0.147] [0.108 0.358 0.288 0.244 0.002] [0.002 0.047 0.053 0.627 0.271]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.002 0.184 0.213 0.524 0.077] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.08039467132550687\n",
      "Val loss: 0.749542 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.005009  [   64/80000]\n",
      "loss: 0.740299  [ 6464/80000]\n",
      "loss: 0.726303  [12864/80000]\n",
      "loss: 0.859980  [19264/80000]\n",
      "loss: 0.648764  [25664/80000]\n",
      "loss: 0.749634  [32064/80000]\n",
      "loss: 1.015990  [38464/80000]\n",
      "loss: 0.776469  [44864/80000]\n",
      "loss: 0.715923  [51264/80000]\n",
      "loss: 0.718338  [57664/80000]\n",
      "loss: 0.766613  [64064/80000]\n",
      "loss: 0.774255  [70464/80000]\n",
      "loss: 0.995315  [76864/80000]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.004 0.004 0.078 0.148 0.766] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.263 0.004 0.055 0.533 0.145] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.613 0.941 0.801 0.746 0.456] [0.243 0.595 0.111 0.048 0.003] [0.033 0.007 0.196 0.023 0.742]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.144 0.179 0.000 0.184 0.492] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.140 0.127 0.001 0.045 0.687] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.308 0.001 0.065 0.013 0.612] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.760 0.024 0.109 0.002 0.105] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.213 0.805 0.964 0.316 0.763] [0.168 0.025 0.774 0.001 0.032] [0.002 0.082 0.032 0.048 0.836]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.110 0.011 0.048 0.503 0.328] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.730 0.996 0.188 0.880 0.120] [0.054 0.131 0.002 0.812 0.002] [0.031 0.011 0.034 0.079 0.846]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.217 0.016 0.121 0.567 0.079] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.848 0.839 0.660 0.531 0.680] [0.065 0.319 0.001 0.002 0.613] [0.237 0.191 0.443 0.122 0.006]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.117 0.438 0.102 0.002 0.341] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.106 0.145 0.062 0.654 0.032] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.269 0.191 0.731 0.853 0.971] [0.012 0.001 0.094 0.580 0.313] [0.011 0.139 0.007 0.812 0.031]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.312 0.054 0.096 0.009 0.529] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.749 0.210 0.882 0.258 0.382] [0.751 0.003 0.230 0.011 0.005] [0.729 0.024 0.009 0.043 0.195]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.076 0.028 0.009 0.378 0.509] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.482 0.024 0.004 0.452 0.038] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.780 0.340 0.406 0.582 0.666] [0.160 0.001 0.004 0.035 0.800] [0.244 0.631 0.108 0.002 0.014]\n",
      "0.06860123337307525\n",
      "Val loss: 0.724511 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.904961  [   64/80000]\n",
      "loss: 0.783786  [ 6464/80000]\n",
      "loss: 0.590207  [12864/80000]\n",
      "loss: 0.852959  [19264/80000]\n",
      "loss: 0.666580  [25664/80000]\n",
      "loss: 0.740628  [32064/80000]\n",
      "loss: 0.851969  [38464/80000]\n",
      "loss: 0.701432  [44864/80000]\n",
      "loss: 0.675445  [51264/80000]\n",
      "loss: 0.721024  [57664/80000]\n",
      "loss: 0.806695  [64064/80000]\n",
      "loss: 0.795638  [70464/80000]\n",
      "loss: 0.957283  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.140 0.108 0.221 0.013 0.518] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.005 0.005 0.086 0.108 0.796] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.613 0.941 0.801 0.746 0.456] [0.301 0.605 0.068 0.023 0.002] [0.033 0.007 0.196 0.023 0.742]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.113 0.160 0.000 0.271 0.456] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.116 0.133 0.000 0.058 0.692] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.504 0.002 0.106 0.014 0.374] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.662 0.042 0.139 0.004 0.152] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.213 0.805 0.964 0.316 0.763] [0.154 0.042 0.746 0.001 0.058] [0.002 0.082 0.032 0.048 0.836]\n",
      "[0.754 0.281 0.028 0.940 0.643] [0.239 0.006 0.054 0.681 0.020] [0.042 0.009 0.001 0.012 0.935]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.115 0.007 0.043 0.359 0.476] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.700 0.999 0.440 0.473 0.703] [0.258 0.520 0.012 0.007 0.202] [0.037 0.001 0.028 0.101 0.832]\n",
      "[0.730 0.996 0.188 0.880 0.120] [0.066 0.227 0.002 0.704 0.001] [0.031 0.011 0.034 0.079 0.846]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.208 0.011 0.085 0.576 0.120] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.147 0.441 0.121 0.002 0.288] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.171 0.160 0.120 0.512 0.037] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.118 0.288 0.950 0.004 0.574] [0.005 0.006 0.715 0.002 0.273] [0.768 0.082 0.007 0.074 0.068]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.259 0.060 0.035 0.008 0.638] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.749 0.210 0.882 0.258 0.382] [0.719 0.003 0.268 0.006 0.004] [0.729 0.024 0.009 0.043 0.195]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.150 0.036 0.039 0.318 0.457] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.617 0.942 0.268 0.656 0.533] [0.147 0.674 0.001 0.161 0.017] [0.160 0.005 0.077 0.252 0.506]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.418 0.076 0.001 0.443 0.062] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.054 0.836 0.173 0.498 0.621] [0.001 0.498 0.001 0.021 0.480] [0.246 0.094 0.457 0.191 0.011]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.195 0.160 0.492 0.152] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.06842967439994874\n",
      "Val loss: 0.710868 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.945599  [   64/80000]\n",
      "loss: 0.777179  [ 6464/80000]\n",
      "loss: 0.617817  [12864/80000]\n",
      "loss: 0.801143  [19264/80000]\n",
      "loss: 0.652689  [25664/80000]\n",
      "loss: 0.767287  [32064/80000]\n",
      "loss: 0.921280  [38464/80000]\n",
      "loss: 0.721184  [44864/80000]\n",
      "loss: 0.791077  [51264/80000]\n",
      "loss: 0.735575  [57664/80000]\n",
      "loss: 0.765806  [64064/80000]\n",
      "loss: 0.853525  [70464/80000]\n",
      "loss: 0.915919  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.105 0.069 0.320 0.011 0.495] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.004 0.005 0.150 0.083 0.758] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.611 0.658 0.942 0.485 0.346] [0.216 0.083 0.670 0.027 0.004] [0.007 0.002 0.035 0.010 0.946]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.258 0.002 0.061 0.587 0.091] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.097 0.139 0.001 0.038 0.726] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.488 0.002 0.086 0.019 0.405] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.479 0.044 0.239 0.004 0.234] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.213 0.805 0.964 0.316 0.763] [0.143 0.040 0.785 0.001 0.031] [0.002 0.082 0.032 0.048 0.836]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.148 0.009 0.049 0.511 0.283] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.730 0.996 0.188 0.880 0.120] [0.037 0.163 0.002 0.797 0.001] [0.031 0.011 0.034 0.079 0.846]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.256 0.018 0.106 0.502 0.118] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.131 0.423 0.149 0.001 0.296] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.106 0.150 0.081 0.624 0.039] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.214 0.050 0.046 0.014 0.676] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.080 0.040 0.013 0.362 0.505] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.526 0.038 0.002 0.412 0.022] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.213 0.094 0.589 0.104] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.06478492216410957\n",
      "Val loss: 0.698389 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.837559  [   64/80000]\n",
      "loss: 0.732330  [ 6464/80000]\n",
      "loss: 0.657712  [12864/80000]\n",
      "loss: 0.824659  [19264/80000]\n",
      "loss: 0.679492  [25664/80000]\n",
      "loss: 0.805211  [32064/80000]\n",
      "loss: 0.851255  [38464/80000]\n",
      "loss: 0.699051  [44864/80000]\n",
      "loss: 0.668672  [51264/80000]\n",
      "loss: 0.743748  [57664/80000]\n",
      "loss: 0.734762  [64064/80000]\n",
      "loss: 0.805028  [70464/80000]\n",
      "loss: 0.892997  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.063 0.090 0.249 0.013 0.585] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.005 0.004 0.094 0.070 0.827] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.155 0.002 0.050 0.736 0.057] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.193 0.151 0.001 0.084 0.571] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.233 0.002 0.120 0.026 0.620] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.062 0.005 0.041 0.644 0.248] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.730 0.996 0.188 0.880 0.120] [0.034 0.169 0.002 0.795 0.000] [0.031 0.011 0.034 0.079 0.846]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.150 0.388 0.164 0.002 0.297] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.091 0.104 0.096 0.677 0.032] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.232 0.060 0.068 0.013 0.627] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.058 0.035 0.018 0.281 0.608] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.469 0.059 0.002 0.441 0.029] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.054 0.836 0.173 0.498 0.621] [0.001 0.503 0.001 0.018 0.478] [0.246 0.094 0.457 0.191 0.011]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.237 0.118 0.602 0.044] [0.158 0.002 0.237 0.560 0.043]\n",
      "[0.780 0.340 0.406 0.582 0.666] [0.103 0.002 0.005 0.075 0.815] [0.244 0.631 0.108 0.002 0.014]\n",
      "0.0643411673452359\n",
      "Val loss: 0.705152 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.942908  [   64/80000]\n",
      "loss: 0.702645  [ 6464/80000]\n",
      "loss: 0.652216  [12864/80000]\n",
      "loss: 0.744326  [19264/80000]\n",
      "loss: 0.715794  [25664/80000]\n",
      "loss: 0.747061  [32064/80000]\n",
      "loss: 0.859452  [38464/80000]\n",
      "loss: 0.683568  [44864/80000]\n",
      "loss: 0.654141  [51264/80000]\n",
      "loss: 0.677363  [57664/80000]\n",
      "loss: 0.688336  [64064/80000]\n",
      "loss: 0.760957  [70464/80000]\n",
      "loss: 0.963851  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.072 0.081 0.272 0.012 0.563] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.003 0.003 0.099 0.043 0.851] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.346 0.002 0.066 0.503 0.083] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.070 0.320 0.000 0.130 0.480] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.177 0.150 0.000 0.052 0.621] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.307 0.002 0.085 0.025 0.582] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.332 0.090 0.369 0.005 0.204] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.097 0.006 0.057 0.670 0.170] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.192 0.008 0.165 0.532 0.104] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.132 0.411 0.161 0.002 0.293] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.085 0.120 0.108 0.655 0.033] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.174 0.075 0.054 0.015 0.682] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.059 0.052 0.029 0.345 0.515] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.370 0.064 0.002 0.515 0.049] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.054 0.836 0.173 0.498 0.621] [0.001 0.461 0.000 0.013 0.525] [0.246 0.094 0.457 0.191 0.011]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.349 0.126 0.471 0.054] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.06233047377989163\n",
      "Val loss: 0.696338 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.886798  [   64/80000]\n",
      "loss: 0.682839  [ 6464/80000]\n",
      "loss: 0.689326  [12864/80000]\n",
      "loss: 0.791197  [19264/80000]\n",
      "loss: 0.688117  [25664/80000]\n",
      "loss: 0.701783  [32064/80000]\n",
      "loss: 0.832682  [38464/80000]\n",
      "loss: 0.614328  [44864/80000]\n",
      "loss: 0.684794  [51264/80000]\n",
      "loss: 0.664915  [57664/80000]\n",
      "loss: 0.672607  [64064/80000]\n",
      "loss: 0.793466  [70464/80000]\n",
      "loss: 0.883599  [76864/80000]\n",
      "[0.970 0.601 0.425 0.519 0.832] [0.584 0.004 0.001 0.135 0.276] [0.063 0.737 0.147 0.013 0.041]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.008 0.007 0.094 0.069 0.822] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.216 0.007 0.068 0.620 0.089] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.177 0.180 0.001 0.055 0.588] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.289 0.004 0.129 0.034 0.544] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.241 0.111 0.363 0.006 0.279] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.213 0.805 0.964 0.316 0.763] [0.163 0.045 0.755 0.001 0.036] [0.002 0.082 0.032 0.048 0.836]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.100 0.006 0.048 0.592 0.253] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.200 0.018 0.147 0.493 0.143] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.213 0.323 0.136 0.001 0.326] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.079 0.122 0.102 0.663 0.034] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.223 0.048 0.056 0.009 0.664] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.076 0.057 0.018 0.327 0.522] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.354 0.056 0.005 0.549 0.036] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.339 0.102 0.502 0.057] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.0621738495312773\n",
      "Val loss: 0.692861 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.833264  [   64/80000]\n",
      "loss: 0.664027  [ 6464/80000]\n",
      "loss: 0.611922  [12864/80000]\n",
      "loss: 0.778436  [19264/80000]\n",
      "loss: 0.593799  [25664/80000]\n",
      "loss: 0.722687  [32064/80000]\n",
      "loss: 0.882001  [38464/80000]\n",
      "loss: 0.651993  [44864/80000]\n",
      "loss: 0.699402  [51264/80000]\n",
      "loss: 0.632821  [57664/80000]\n",
      "loss: 0.741946  [64064/80000]\n",
      "loss: 0.787744  [70464/80000]\n",
      "loss: 0.962290  [76864/80000]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.009 0.007 0.143 0.069 0.773] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.194 0.004 0.086 0.596 0.120] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.687 0.841 0.667 0.277 0.485] [0.011 0.610 0.138 0.003 0.238] [0.654 0.172 0.075 0.039 0.059]\n",
      "[0.421 0.649 0.765 0.451 0.347] [0.002 0.032 0.706 0.001 0.258] [0.132 0.408 0.029 0.422 0.008]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.155 0.151 0.000 0.052 0.641] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.319 0.002 0.092 0.031 0.555] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.366 0.087 0.403 0.007 0.136] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.103 0.006 0.061 0.596 0.234] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.186 0.013 0.165 0.549 0.087] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.178 0.377 0.161 0.001 0.283] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.065 0.130 0.141 0.630 0.033] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.216 0.042 0.036 0.010 0.697] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.067 0.039 0.029 0.309 0.556] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.328 0.040 0.004 0.600 0.028] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.349 0.091 0.521 0.039] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.06361020487948957\n",
      "Val loss: 0.692819 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.885126  [   64/80000]\n",
      "loss: 0.696013  [ 6464/80000]\n",
      "loss: 0.692653  [12864/80000]\n",
      "loss: 0.814192  [19264/80000]\n",
      "loss: 0.575294  [25664/80000]\n",
      "loss: 0.706322  [32064/80000]\n",
      "loss: 0.896437  [38464/80000]\n",
      "loss: 0.653431  [44864/80000]\n",
      "loss: 0.691114  [51264/80000]\n",
      "loss: 0.611814  [57664/80000]\n",
      "loss: 0.738208  [64064/80000]\n",
      "loss: 0.846611  [70464/80000]\n",
      "loss: 0.854374  [76864/80000]\n",
      "[0.970 0.601 0.425 0.519 0.832] [0.635 0.004 0.001 0.164 0.197] [0.063 0.737 0.147 0.013 0.041]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.079 0.100 0.274 0.016 0.531] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.014 0.007 0.092 0.094 0.793] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.307 0.003 0.102 0.424 0.164] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.180 0.149 0.001 0.211 0.459] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.177 0.151 0.000 0.068 0.603] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.282 0.005 0.115 0.038 0.560] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.449 0.070 0.351 0.006 0.123] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.095 0.008 0.063 0.565 0.269] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.194 0.018 0.146 0.537 0.105] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.177 0.397 0.155 0.002 0.269] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.072 0.124 0.101 0.666 0.037] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.163 0.052 0.053 0.013 0.719] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.054 0.036 0.022 0.309 0.579] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.360 0.033 0.006 0.570 0.031] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.307 0.078 0.566 0.048] [0.158 0.002 0.237 0.560 0.043]\n",
      "[0.780 0.340 0.406 0.582 0.666] [0.129 0.001 0.006 0.054 0.810] [0.244 0.631 0.108 0.002 0.014]\n",
      "0.06402095643516394\n",
      "Val loss: 0.696360 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.887460  [   64/80000]\n",
      "loss: 0.743571  [ 6464/80000]\n",
      "loss: 0.609894  [12864/80000]\n",
      "loss: 0.799603  [19264/80000]\n",
      "loss: 0.656919  [25664/80000]\n",
      "loss: 0.673057  [32064/80000]\n",
      "loss: 0.921602  [38464/80000]\n",
      "loss: 0.608631  [44864/80000]\n",
      "loss: 0.709905  [51264/80000]\n",
      "loss: 0.671624  [57664/80000]\n",
      "loss: 0.722122  [64064/80000]\n",
      "loss: 0.748746  [70464/80000]\n",
      "loss: 0.867167  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.071 0.091 0.290 0.012 0.536] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.007 0.007 0.113 0.099 0.775] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.270 0.003 0.099 0.532 0.095] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.213 0.190 0.001 0.051 0.544] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.337 0.002 0.093 0.026 0.541] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.405 0.117 0.278 0.011 0.189] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.102 0.004 0.063 0.632 0.198] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.193 0.017 0.124 0.530 0.136] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.168 0.444 0.137 0.001 0.249] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.084 0.142 0.100 0.646 0.028] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.214 0.064 0.056 0.015 0.650] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.067 0.044 0.027 0.409 0.454] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.350 0.043 0.003 0.580 0.025] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.287 0.094 0.581 0.038] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.06152291015735297\n",
      "Val loss: 0.686932 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.876495  [   64/80000]\n",
      "loss: 0.742508  [ 6464/80000]\n",
      "loss: 0.632531  [12864/80000]\n",
      "loss: 0.808704  [19264/80000]\n",
      "loss: 0.634715  [25664/80000]\n",
      "loss: 0.697124  [32064/80000]\n",
      "loss: 0.840438  [38464/80000]\n",
      "loss: 0.688299  [44864/80000]\n",
      "loss: 0.705821  [51264/80000]\n",
      "loss: 0.711308  [57664/80000]\n",
      "loss: 0.800737  [64064/80000]\n",
      "loss: 0.766935  [70464/80000]\n",
      "loss: 0.949821  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.075 0.114 0.318 0.016 0.477] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.007 0.007 0.116 0.088 0.782] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.270 0.003 0.052 0.620 0.056] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.157 0.224 0.001 0.059 0.560] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.350 0.004 0.139 0.031 0.476] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.247 0.123 0.397 0.005 0.228] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.009 0.665 0.524 0.593 0.762] [0.000 0.181 0.094 0.386 0.339] [0.634 0.117 0.032 0.022 0.195]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.059 0.004 0.043 0.718 0.176] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.118 0.015 0.114 0.608 0.146] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.147 0.360 0.167 0.001 0.324] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.058 0.133 0.101 0.682 0.027] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.139 0.044 0.026 0.005 0.786] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.749 0.210 0.882 0.258 0.382] [0.738 0.002 0.254 0.005 0.001] [0.729 0.024 0.009 0.043 0.195]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.058 0.061 0.030 0.484 0.367] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.411 0.036 0.003 0.526 0.025] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.240 0.095 0.650 0.014] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.05917130063747674\n",
      "Val loss: 0.690886 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.839706  [   64/80000]\n",
      "loss: 0.666396  [ 6464/80000]\n",
      "loss: 0.626533  [12864/80000]\n",
      "loss: 0.762840  [19264/80000]\n",
      "loss: 0.621434  [25664/80000]\n",
      "loss: 0.740146  [32064/80000]\n",
      "loss: 0.886433  [38464/80000]\n",
      "loss: 0.686602  [44864/80000]\n",
      "loss: 0.702946  [51264/80000]\n",
      "loss: 0.667635  [57664/80000]\n",
      "loss: 0.646918  [64064/80000]\n",
      "loss: 0.779438  [70464/80000]\n",
      "loss: 0.957559  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.050 0.075 0.308 0.012 0.555] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.006 0.002 0.060 0.070 0.862] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.286 0.002 0.093 0.544 0.075] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.932 0.728 0.064 0.537 0.281] [0.784 0.020 0.000 0.002 0.194] [0.141 0.057 0.363 0.433 0.006]\n",
      "[0.792 0.727 0.431 0.316 0.617] [0.296 0.464 0.221 0.001 0.018] [0.099 0.218 0.018 0.253 0.413]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.171 0.160 0.000 0.045 0.624] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.400 0.001 0.039 0.022 0.538] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.373 0.131 0.371 0.004 0.120] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.086 0.003 0.055 0.698 0.158] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.171 0.010 0.117 0.596 0.107] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.158 0.392 0.181 0.001 0.269] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.052 0.135 0.104 0.685 0.023] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.144 0.035 0.026 0.005 0.790] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.070 0.031 0.019 0.417 0.463] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.453 0.057 0.004 0.469 0.017] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.301 0.094 0.573 0.032] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.05987660654096025\n",
      "Val loss: 0.684420 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.798901  [   64/80000]\n",
      "loss: 0.693274  [ 6464/80000]\n",
      "loss: 0.722952  [12864/80000]\n",
      "loss: 0.749812  [19264/80000]\n",
      "loss: 0.640799  [25664/80000]\n",
      "loss: 0.742231  [32064/80000]\n",
      "loss: 0.876351  [38464/80000]\n",
      "loss: 0.706887  [44864/80000]\n",
      "loss: 0.696156  [51264/80000]\n",
      "loss: 0.680711  [57664/80000]\n",
      "loss: 0.742154  [64064/80000]\n",
      "loss: 0.807275  [70464/80000]\n",
      "loss: 0.872774  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.054 0.087 0.338 0.014 0.507] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.007 0.004 0.163 0.115 0.712] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.262 0.003 0.088 0.573 0.075] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.156 0.180 0.000 0.254 0.410] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.172 0.161 0.000 0.048 0.618] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.425 0.002 0.097 0.029 0.447] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.071 0.004 0.058 0.671 0.196] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.151 0.011 0.133 0.604 0.101] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.160 0.400 0.183 0.001 0.257] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.054 0.166 0.105 0.645 0.030] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.150 0.037 0.019 0.004 0.791] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.063 0.027 0.013 0.468 0.430] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.332 0.038 0.003 0.603 0.025] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.328 0.207 0.443 0.022] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.05950975333008751\n",
      "Val loss: 0.686779 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.839553  [   64/80000]\n",
      "loss: 0.664482  [ 6464/80000]\n",
      "loss: 0.678058  [12864/80000]\n",
      "loss: 0.784840  [19264/80000]\n",
      "loss: 0.639959  [25664/80000]\n",
      "loss: 0.679545  [32064/80000]\n",
      "loss: 0.879257  [38464/80000]\n",
      "loss: 0.601055  [44864/80000]\n",
      "loss: 0.706955  [51264/80000]\n",
      "loss: 0.708331  [57664/80000]\n",
      "loss: 0.720145  [64064/80000]\n",
      "loss: 0.793295  [70464/80000]\n",
      "loss: 0.839796  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.064 0.125 0.318 0.012 0.481] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.008 0.003 0.149 0.154 0.687] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.289 0.003 0.105 0.521 0.082] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.144 0.265 0.000 0.237 0.354] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.175 0.184 0.000 0.065 0.576] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.477 0.001 0.098 0.032 0.391] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.413 0.040 0.376 0.003 0.167] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.110 0.004 0.077 0.587 0.223] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.161 0.009 0.111 0.597 0.122] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.159 0.338 0.161 0.001 0.342] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.080 0.120 0.128 0.639 0.034] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.150 0.056 0.021 0.005 0.767] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.073 0.055 0.016 0.490 0.366] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.393 0.057 0.003 0.523 0.024] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.294 0.142 0.551 0.012] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.05959868148437933\n",
      "Val loss: 0.679464 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.822276  [   64/80000]\n",
      "loss: 0.647193  [ 6464/80000]\n",
      "loss: 0.725260  [12864/80000]\n",
      "loss: 0.850774  [19264/80000]\n",
      "loss: 0.673753  [25664/80000]\n",
      "loss: 0.708816  [32064/80000]\n",
      "loss: 0.848434  [38464/80000]\n",
      "loss: 0.714090  [44864/80000]\n",
      "loss: 0.746581  [51264/80000]\n",
      "loss: 0.671308  [57664/80000]\n",
      "loss: 0.708599  [64064/80000]\n",
      "loss: 0.781939  [70464/80000]\n",
      "loss: 0.920778  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.069 0.164 0.287 0.009 0.472] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.005 0.005 0.128 0.111 0.751] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.611 0.658 0.942 0.485 0.346] [0.162 0.129 0.683 0.024 0.002] [0.007 0.002 0.035 0.010 0.946]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.137 0.165 0.000 0.242 0.456] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.143 0.193 0.001 0.062 0.601] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.499 0.001 0.076 0.016 0.407] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.305 0.143 0.333 0.005 0.213] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.076 0.002 0.048 0.720 0.153] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.157 0.014 0.128 0.559 0.141] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.154 0.414 0.140 0.001 0.291] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.061 0.146 0.084 0.683 0.025] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.066 0.520 0.706 0.346 0.308] [0.000 0.004 0.671 0.323 0.001] [0.193 0.609 0.127 0.003 0.068]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.138 0.073 0.023 0.008 0.757] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.079 0.055 0.018 0.399 0.449] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.357 0.044 0.005 0.563 0.031] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.365 0.162 0.461 0.012] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.058325289400643056\n",
      "Val loss: 0.679801 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.875001  [   64/80000]\n",
      "loss: 0.622404  [ 6464/80000]\n",
      "loss: 0.726130  [12864/80000]\n",
      "loss: 0.682517  [19264/80000]\n",
      "loss: 0.608466  [25664/80000]\n",
      "loss: 0.697968  [32064/80000]\n",
      "loss: 0.836563  [38464/80000]\n",
      "loss: 0.659698  [44864/80000]\n",
      "loss: 0.688996  [51264/80000]\n",
      "loss: 0.704202  [57664/80000]\n",
      "loss: 0.663325  [64064/80000]\n",
      "loss: 0.781799  [70464/80000]\n",
      "loss: 0.921401  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.118 0.128 0.324 0.014 0.415] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.004 0.001 0.218 0.096 0.681] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.611 0.658 0.942 0.485 0.346] [0.162 0.134 0.678 0.024 0.002] [0.007 0.002 0.035 0.010 0.946]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.255 0.003 0.100 0.550 0.091] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.792 0.727 0.431 0.316 0.617] [0.253 0.523 0.200 0.001 0.024] [0.099 0.218 0.018 0.253 0.413]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.165 0.252 0.000 0.066 0.517] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.556 0.001 0.093 0.019 0.331] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.439 0.101 0.339 0.004 0.118] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.009 0.665 0.524 0.593 0.762] [0.000 0.301 0.109 0.331 0.258] [0.634 0.117 0.032 0.022 0.195]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.111 0.003 0.057 0.636 0.193] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.170 0.013 0.159 0.565 0.093] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.145 0.373 0.141 0.001 0.340] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.073 0.148 0.126 0.629 0.025] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.066 0.520 0.706 0.346 0.308] [0.000 0.009 0.693 0.297 0.001] [0.193 0.609 0.127 0.003 0.068]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.167 0.062 0.026 0.005 0.740] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.077 0.052 0.018 0.494 0.360] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.411 0.033 0.003 0.528 0.025] [0.013 0.012 0.036 0.091 0.848]\n",
      "0.06028182255328882\n",
      "Val loss: 0.683818 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.790343  [   64/80000]\n",
      "loss: 0.623805  [ 6464/80000]\n",
      "loss: 0.775186  [12864/80000]\n",
      "loss: 0.709006  [19264/80000]\n",
      "loss: 0.625854  [25664/80000]\n",
      "loss: 0.719321  [32064/80000]\n",
      "loss: 0.845226  [38464/80000]\n",
      "loss: 0.690803  [44864/80000]\n",
      "loss: 0.744009  [51264/80000]\n",
      "loss: 0.660665  [57664/80000]\n",
      "loss: 0.670303  [64064/80000]\n",
      "loss: 0.818986  [70464/80000]\n",
      "loss: 0.895201  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.048 0.143 0.365 0.014 0.430] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.005 0.003 0.153 0.124 0.716] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.257 0.002 0.079 0.577 0.085] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.096 0.175 0.000 0.287 0.441] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.118 0.102 0.000 0.034 0.746] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.450 0.003 0.114 0.031 0.403] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.060 0.001 0.053 0.795 0.090] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.129 0.022 0.126 0.578 0.146] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.165 0.350 0.188 0.001 0.295] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.051 0.142 0.081 0.705 0.021] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.066 0.520 0.706 0.346 0.308] [0.001 0.016 0.629 0.353 0.002] [0.193 0.609 0.127 0.003 0.068]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.147 0.036 0.009 0.004 0.805] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.040 0.044 0.015 0.564 0.337] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.294 0.031 0.002 0.652 0.021] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.288 0.065 0.631 0.017] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.0583220184291346\n",
      "Val loss: 0.690870 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.954971  [   64/80000]\n",
      "loss: 0.665737  [ 6464/80000]\n",
      "loss: 0.712664  [12864/80000]\n",
      "loss: 0.824250  [19264/80000]\n",
      "loss: 0.643336  [25664/80000]\n",
      "loss: 0.695081  [32064/80000]\n",
      "loss: 0.857624  [38464/80000]\n",
      "loss: 0.668886  [44864/80000]\n",
      "loss: 0.651322  [51264/80000]\n",
      "loss: 0.630905  [57664/80000]\n",
      "loss: 0.677670  [64064/80000]\n",
      "loss: 0.770922  [70464/80000]\n",
      "loss: 0.898123  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.045 0.080 0.341 0.013 0.521] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.008 0.002 0.132 0.114 0.745] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.267 0.001 0.060 0.573 0.099] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.196 0.199 0.000 0.185 0.420] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.116 0.159 0.000 0.041 0.684] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.394 0.003 0.070 0.022 0.510] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.450 0.092 0.326 0.002 0.130] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.009 0.665 0.524 0.593 0.762] [0.000 0.169 0.134 0.368 0.329] [0.634 0.117 0.032 0.022 0.195]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.075 0.002 0.050 0.730 0.144] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.168 0.010 0.123 0.583 0.115] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.177 0.354 0.156 0.001 0.312] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.060 0.124 0.107 0.683 0.026] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.206 0.063 0.024 0.007 0.701] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.042 0.022 0.018 0.520 0.398] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.477 0.072 0.002 0.432 0.016] [0.013 0.012 0.036 0.091 0.848]\n",
      "0.0575365080490874\n",
      "Val loss: 0.684454 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.953220  [   64/80000]\n",
      "loss: 0.688939  [ 6464/80000]\n",
      "loss: 0.672954  [12864/80000]\n",
      "loss: 0.758015  [19264/80000]\n",
      "loss: 0.614445  [25664/80000]\n",
      "loss: 0.658866  [32064/80000]\n",
      "loss: 0.822834  [38464/80000]\n",
      "loss: 0.661990  [44864/80000]\n",
      "loss: 0.660006  [51264/80000]\n",
      "loss: 0.644300  [57664/80000]\n",
      "loss: 0.675845  [64064/80000]\n",
      "loss: 0.772501  [70464/80000]\n",
      "loss: 0.897472  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.044 0.090 0.395 0.006 0.466] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.006 0.002 0.210 0.094 0.689] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.355 0.001 0.062 0.509 0.073] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.083 0.200 0.000 0.240 0.477] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.143 0.186 0.000 0.039 0.632] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.491 0.001 0.086 0.016 0.407] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.009 0.665 0.524 0.593 0.762] [0.000 0.206 0.106 0.333 0.355] [0.634 0.117 0.032 0.022 0.195]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.094 0.002 0.055 0.716 0.133] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.173 0.010 0.149 0.496 0.172] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.164 0.302 0.203 0.001 0.329] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.058 0.112 0.091 0.715 0.025] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.953 0.415 0.739 0.156 0.602] [0.486 0.000 0.510 0.000 0.003] [0.029 0.082 0.253 0.149 0.487]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.172 0.063 0.016 0.003 0.747] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.050 0.026 0.007 0.518 0.399] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.362 0.027 0.003 0.586 0.023] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.282 0.180 0.521 0.017] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.05826820295689433\n",
      "Val loss: 0.680451 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.821624  [   64/80000]\n",
      "loss: 0.722299  [ 6464/80000]\n",
      "loss: 0.724258  [12864/80000]\n",
      "loss: 0.761562  [19264/80000]\n",
      "loss: 0.571842  [25664/80000]\n",
      "loss: 0.720892  [32064/80000]\n",
      "loss: 0.860716  [38464/80000]\n",
      "loss: 0.625476  [44864/80000]\n",
      "loss: 0.656421  [51264/80000]\n",
      "loss: 0.644184  [57664/80000]\n",
      "loss: 0.691408  [64064/80000]\n",
      "loss: 0.772942  [70464/80000]\n",
      "loss: 0.893690  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.048 0.126 0.336 0.011 0.478] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.008 0.001 0.146 0.102 0.742] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.611 0.658 0.942 0.485 0.346] [0.198 0.152 0.623 0.024 0.002] [0.007 0.002 0.035 0.010 0.946]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.194 0.127 0.000 0.039 0.640] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.428 0.001 0.077 0.016 0.478] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.471 0.073 0.347 0.004 0.104] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.009 0.665 0.524 0.593 0.762] [0.000 0.272 0.124 0.324 0.280] [0.634 0.117 0.032 0.022 0.195]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.109 0.001 0.051 0.670 0.168] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.245 0.011 0.167 0.453 0.124] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.159 0.335 0.163 0.001 0.343] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.064 0.135 0.101 0.675 0.026] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.173 0.033 0.011 0.008 0.775] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.077 0.037 0.019 0.480 0.387] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.554 0.059 0.005 0.364 0.019] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.054 0.836 0.173 0.498 0.621] [0.000 0.508 0.000 0.006 0.486] [0.246 0.094 0.457 0.191 0.011]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.270 0.080 0.632 0.018] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.0589535224993983\n",
      "Val loss: 0.675503 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.884264  [   64/80000]\n",
      "loss: 0.735834  [ 6464/80000]\n",
      "loss: 0.735762  [12864/80000]\n",
      "loss: 0.710116  [19264/80000]\n",
      "loss: 0.664702  [25664/80000]\n",
      "loss: 0.662158  [32064/80000]\n",
      "loss: 0.834251  [38464/80000]\n",
      "loss: 0.678062  [44864/80000]\n",
      "loss: 0.696611  [51264/80000]\n",
      "loss: 0.697554  [57664/80000]\n",
      "loss: 0.694387  [64064/80000]\n",
      "loss: 0.803424  [70464/80000]\n",
      "loss: 0.827805  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.050 0.105 0.350 0.007 0.487] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.013 0.002 0.262 0.110 0.613] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.285 0.001 0.071 0.595 0.049] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.169 0.130 0.001 0.240 0.460] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.792 0.727 0.431 0.316 0.617] [0.209 0.558 0.230 0.001 0.002] [0.099 0.218 0.018 0.253 0.413]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.140 0.196 0.000 0.028 0.636] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.476 0.001 0.090 0.012 0.421] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.009 0.665 0.524 0.593 0.762] [0.000 0.330 0.145 0.295 0.229] [0.634 0.117 0.032 0.022 0.195]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.093 0.002 0.059 0.708 0.138] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.176 0.013 0.145 0.551 0.115] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.168 0.351 0.164 0.001 0.314] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.043 0.129 0.110 0.696 0.022] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.066 0.520 0.706 0.346 0.308] [0.000 0.004 0.700 0.295 0.001] [0.193 0.609 0.127 0.003 0.068]\n",
      "[0.953 0.415 0.739 0.156 0.602] [0.517 0.000 0.481 0.001 0.001] [0.029 0.082 0.253 0.149 0.487]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.168 0.066 0.027 0.006 0.732] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.045 0.034 0.020 0.506 0.394] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.433 0.110 0.004 0.437 0.015] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.224 0.215 0.534 0.026] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.05746210940769915\n",
      "Val loss: 0.685350 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.894778  [   64/80000]\n",
      "loss: 0.610080  [ 6464/80000]\n",
      "loss: 0.727303  [12864/80000]\n",
      "loss: 0.782804  [19264/80000]\n",
      "loss: 0.673413  [25664/80000]\n",
      "loss: 0.742570  [32064/80000]\n",
      "loss: 0.837412  [38464/80000]\n",
      "loss: 0.648650  [44864/80000]\n",
      "loss: 0.621715  [51264/80000]\n",
      "loss: 0.612753  [57664/80000]\n",
      "loss: 0.666323  [64064/80000]\n",
      "loss: 0.790187  [70464/80000]\n",
      "loss: 0.875045  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.047 0.101 0.332 0.007 0.513] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.010 0.003 0.141 0.103 0.744] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.123 0.177 0.000 0.211 0.489] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.127 0.167 0.000 0.032 0.674] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.551 0.001 0.076 0.011 0.362] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.343 0.145 0.363 0.002 0.146] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.009 0.665 0.524 0.593 0.762] [0.000 0.358 0.101 0.252 0.288] [0.634 0.117 0.032 0.022 0.195]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.087 0.002 0.046 0.687 0.179] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.178 0.008 0.146 0.551 0.117] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.187 0.298 0.164 0.001 0.352] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.031 0.166 0.054 0.729 0.020] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.187 0.071 0.026 0.005 0.711] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.045 0.025 0.009 0.482 0.439] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.577 0.046 0.002 0.353 0.022] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.001 0.270 0.243 0.475 0.011] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.0565844494851085\n",
      "Val loss: 0.680372 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.853488  [   64/80000]\n",
      "loss: 0.741857  [ 6464/80000]\n",
      "loss: 0.639566  [12864/80000]\n",
      "loss: 0.748167  [19264/80000]\n",
      "loss: 0.612775  [25664/80000]\n",
      "loss: 0.711127  [32064/80000]\n",
      "loss: 0.860831  [38464/80000]\n",
      "loss: 0.674022  [44864/80000]\n",
      "loss: 0.732088  [51264/80000]\n",
      "loss: 0.663491  [57664/80000]\n",
      "loss: 0.640057  [64064/80000]\n",
      "loss: 0.806285  [70464/80000]\n",
      "loss: 0.947685  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.050 0.109 0.358 0.008 0.475] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.016 0.002 0.168 0.195 0.618] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.183 0.155 0.000 0.213 0.449] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.199 0.178 0.000 0.028 0.594] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.504 0.001 0.069 0.017 0.409] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.402 0.080 0.391 0.005 0.122] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.009 0.665 0.524 0.593 0.762] [0.000 0.297 0.121 0.292 0.290] [0.634 0.117 0.032 0.022 0.195]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.095 0.001 0.055 0.732 0.116] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.178 0.014 0.152 0.588 0.068] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.203 0.310 0.164 0.001 0.323] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.040 0.172 0.114 0.652 0.021] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.226 0.049 0.013 0.004 0.707] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.047 0.044 0.016 0.527 0.366] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.380 0.049 0.003 0.555 0.013] [0.013 0.012 0.036 0.091 0.848]\n",
      "0.05797971714268706\n",
      "Val loss: 0.680115 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.835373  [   64/80000]\n",
      "loss: 0.652377  [ 6464/80000]\n",
      "loss: 0.692020  [12864/80000]\n",
      "loss: 0.779339  [19264/80000]\n",
      "loss: 0.587750  [25664/80000]\n",
      "loss: 0.668641  [32064/80000]\n",
      "loss: 0.801441  [38464/80000]\n",
      "loss: 0.676415  [44864/80000]\n",
      "loss: 0.658458  [51264/80000]\n",
      "loss: 0.607495  [57664/80000]\n",
      "loss: 0.636190  [64064/80000]\n",
      "loss: 0.808306  [70464/80000]\n",
      "loss: 0.891738  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.044 0.114 0.388 0.012 0.441] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.005 0.002 0.080 0.092 0.821] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.328 0.002 0.086 0.483 0.101] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.792 0.727 0.431 0.316 0.617] [0.358 0.416 0.220 0.001 0.006] [0.099 0.218 0.018 0.253 0.413]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.168 0.169 0.000 0.037 0.626] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.423 0.002 0.062 0.020 0.493] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.009 0.665 0.524 0.593 0.762] [0.000 0.245 0.143 0.289 0.322] [0.634 0.117 0.032 0.022 0.195]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.069 0.002 0.062 0.659 0.208] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.147 0.008 0.121 0.611 0.113] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.171 0.335 0.184 0.001 0.310] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.051 0.186 0.099 0.640 0.023] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.226 0.059 0.022 0.007 0.685] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.076 0.042 0.010 0.523 0.349] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.358 0.062 0.006 0.559 0.016] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.241 0.162 0.579 0.018] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.0579852797271177\n",
      "Val loss: 0.681919 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.848920  [   64/80000]\n",
      "loss: 0.659099  [ 6464/80000]\n",
      "loss: 0.738599  [12864/80000]\n",
      "loss: 0.725902  [19264/80000]\n",
      "loss: 0.561569  [25664/80000]\n",
      "loss: 0.665024  [32064/80000]\n",
      "loss: 0.842237  [38464/80000]\n",
      "loss: 0.674390  [44864/80000]\n",
      "loss: 0.633207  [51264/80000]\n",
      "loss: 0.621646  [57664/80000]\n",
      "loss: 0.693499  [64064/80000]\n",
      "loss: 0.741172  [70464/80000]\n",
      "loss: 0.941609  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.064 0.162 0.298 0.008 0.468] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.013 0.001 0.152 0.164 0.669] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.309 0.002 0.059 0.558 0.071] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.149 0.201 0.001 0.186 0.464] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.153 0.230 0.000 0.040 0.576] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.515 0.001 0.071 0.015 0.397] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.364 0.131 0.376 0.004 0.126] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.009 0.665 0.524 0.593 0.762] [0.000 0.329 0.131 0.283 0.258] [0.634 0.117 0.032 0.022 0.195]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.096 0.002 0.044 0.723 0.135] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.188 0.013 0.148 0.561 0.091] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.158 0.340 0.150 0.001 0.352] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.055 0.206 0.066 0.652 0.020] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.066 0.520 0.706 0.346 0.308] [0.000 0.010 0.694 0.296 0.001] [0.193 0.609 0.127 0.003 0.068]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.148 0.057 0.020 0.005 0.771] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.075 0.067 0.008 0.569 0.280] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.511 0.034 0.003 0.432 0.019] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.316 0.113 0.566 0.005] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.05734440108878772\n",
      "Val loss: 0.681730 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.905911  [   64/80000]\n",
      "loss: 0.664817  [ 6464/80000]\n",
      "loss: 0.707094  [12864/80000]\n",
      "loss: 0.739624  [19264/80000]\n",
      "loss: 0.644404  [25664/80000]\n",
      "loss: 0.759567  [32064/80000]\n",
      "loss: 0.792554  [38464/80000]\n",
      "loss: 0.710479  [44864/80000]\n",
      "loss: 0.627942  [51264/80000]\n",
      "loss: 0.647540  [57664/80000]\n",
      "loss: 0.630767  [64064/80000]\n",
      "loss: 0.778619  [70464/80000]\n",
      "loss: 0.893376  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.056 0.148 0.328 0.006 0.462] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.005 0.002 0.185 0.107 0.701] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.792 0.727 0.431 0.316 0.617] [0.253 0.504 0.239 0.000 0.004] [0.099 0.218 0.018 0.253 0.413]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.158 0.133 0.000 0.025 0.684] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.471 0.001 0.065 0.013 0.450] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.009 0.665 0.524 0.593 0.762] [0.000 0.315 0.115 0.335 0.235] [0.634 0.117 0.032 0.022 0.195]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.093 0.002 0.064 0.709 0.132] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.152 0.009 0.161 0.591 0.087] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.200 0.362 0.178 0.001 0.259] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.052 0.176 0.134 0.619 0.019] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.151 0.031 0.012 0.003 0.804] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.599 0.018 0.331 0.458 0.790] [0.494 0.002 0.000 0.014 0.490] [0.180 0.072 0.628 0.054 0.065]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.064 0.038 0.009 0.569 0.321] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.442 0.054 0.002 0.490 0.012] [0.013 0.012 0.036 0.091 0.848]\n",
      "0.05629169920136601\n",
      "Val loss: 0.681479 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.820457  [   64/80000]\n",
      "loss: 0.750016  [ 6464/80000]\n",
      "loss: 0.652311  [12864/80000]\n",
      "loss: 0.786580  [19264/80000]\n",
      "loss: 0.625730  [25664/80000]\n",
      "loss: 0.662301  [32064/80000]\n",
      "loss: 0.880577  [38464/80000]\n",
      "loss: 0.657412  [44864/80000]\n",
      "loss: 0.679320  [51264/80000]\n",
      "loss: 0.703519  [57664/80000]\n",
      "loss: 0.605158  [64064/80000]\n",
      "loss: 0.757024  [70464/80000]\n",
      "loss: 0.878967  [76864/80000]\n",
      "[0.970 0.601 0.425 0.519 0.832] [0.665 0.002 0.001 0.208 0.125] [0.063 0.737 0.147 0.013 0.041]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.059 0.111 0.408 0.007 0.416] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.013 0.001 0.268 0.115 0.603] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.224 0.001 0.050 0.676 0.049] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.192 0.153 0.000 0.189 0.466] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.195 0.173 0.000 0.043 0.588] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.507 0.001 0.070 0.013 0.409] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.009 0.665 0.524 0.593 0.762] [0.000 0.177 0.216 0.292 0.315] [0.634 0.117 0.032 0.022 0.195]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.083 0.001 0.041 0.755 0.120] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.161 0.004 0.138 0.595 0.101] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.190 0.356 0.179 0.001 0.274] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.040 0.162 0.089 0.683 0.025] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.953 0.415 0.739 0.156 0.602] [0.498 0.000 0.500 0.001 0.001] [0.029 0.082 0.253 0.149 0.487]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.223 0.068 0.021 0.006 0.682] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.055 0.036 0.010 0.487 0.413] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.432 0.061 0.003 0.491 0.014] [0.013 0.012 0.036 0.091 0.848]\n",
      "0.057252958185016155\n",
      "Val loss: 0.680252 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.830961  [   64/80000]\n",
      "loss: 0.671421  [ 6464/80000]\n",
      "loss: 0.763462  [12864/80000]\n",
      "loss: 0.787713  [19264/80000]\n",
      "loss: 0.601831  [25664/80000]\n",
      "loss: 0.742392  [32064/80000]\n",
      "loss: 0.815890  [38464/80000]\n",
      "loss: 0.672408  [44864/80000]\n",
      "loss: 0.674210  [51264/80000]\n",
      "loss: 0.716252  [57664/80000]\n",
      "loss: 0.654027  [64064/80000]\n",
      "loss: 0.757155  [70464/80000]\n",
      "loss: 0.898617  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.058 0.111 0.371 0.009 0.450] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.011 0.002 0.223 0.113 0.651] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.164 0.194 0.001 0.198 0.444] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.169 0.218 0.000 0.052 0.561] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.427 0.001 0.093 0.021 0.458] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.555 0.549 0.736 0.249 0.597] [0.402 0.080 0.418 0.003 0.097] [0.012 0.033 0.009 0.042 0.904]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.102 0.001 0.067 0.705 0.126] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.199 0.009 0.195 0.475 0.122] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.164 0.354 0.187 0.001 0.295] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.041 0.174 0.102 0.658 0.025] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.953 0.415 0.739 0.156 0.602] [0.510 0.001 0.486 0.000 0.004] [0.029 0.082 0.253 0.149 0.487]\n",
      "[0.269 0.191 0.731 0.853 0.971] [0.010 0.001 0.184 0.451 0.354] [0.011 0.139 0.007 0.812 0.031]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.193 0.039 0.015 0.005 0.747] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.071 0.048 0.018 0.532 0.332] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.516 0.046 0.004 0.417 0.017] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.262 0.202 0.525 0.010] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.058331359671920255\n",
      "Val loss: 0.680053 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.817602  [   64/80000]\n",
      "loss: 0.671470  [ 6464/80000]\n",
      "loss: 0.636453  [12864/80000]\n",
      "loss: 0.753064  [19264/80000]\n",
      "loss: 0.614270  [25664/80000]\n",
      "loss: 0.702214  [32064/80000]\n",
      "loss: 0.824417  [38464/80000]\n",
      "loss: 0.702954  [44864/80000]\n",
      "loss: 0.625136  [51264/80000]\n",
      "loss: 0.652555  [57664/80000]\n",
      "loss: 0.615544  [64064/80000]\n",
      "loss: 0.748499  [70464/80000]\n",
      "loss: 0.946493  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.047 0.184 0.370 0.005 0.394] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.006 0.005 0.170 0.114 0.704] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.360 0.001 0.066 0.504 0.069] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.152 0.146 0.000 0.253 0.448] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.172 0.237 0.000 0.050 0.542] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.463 0.002 0.058 0.007 0.470] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.009 0.665 0.524 0.593 0.762] [0.000 0.195 0.186 0.328 0.291] [0.634 0.117 0.032 0.022 0.195]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.073 0.001 0.051 0.729 0.145] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.199 0.362 0.187 0.000 0.252] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.040 0.124 0.080 0.734 0.022] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.192 0.073 0.016 0.004 0.714] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.039 0.037 0.010 0.655 0.259] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.428 0.042 0.002 0.519 0.009] [0.013 0.012 0.036 0.091 0.848]\n",
      "[0.105 0.427 0.752 0.805 0.474] [0.000 0.339 0.161 0.484 0.016] [0.158 0.002 0.237 0.560 0.043]\n",
      "0.057176493495248\n",
      "Val loss: 0.684134 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.815267  [   64/80000]\n",
      "loss: 0.687604  [ 6464/80000]\n",
      "loss: 0.638631  [12864/80000]\n",
      "loss: 0.784271  [19264/80000]\n",
      "loss: 0.616352  [25664/80000]\n",
      "loss: 0.713455  [32064/80000]\n",
      "loss: 0.786904  [38464/80000]\n",
      "loss: 0.674318  [44864/80000]\n",
      "loss: 0.671828  [51264/80000]\n",
      "loss: 0.596037  [57664/80000]\n",
      "loss: 0.627851  [64064/80000]\n",
      "loss: 0.704788  [70464/80000]\n",
      "loss: 0.881622  [76864/80000]\n",
      "[0.540 0.652 0.350 0.089 0.680] [0.062 0.169 0.364 0.007 0.399] [0.903 0.056 0.001 0.032 0.009]\n",
      "[0.001 0.033 0.567 0.453 0.113] [0.010 0.002 0.209 0.175 0.604] [0.026 0.030 0.027 0.916 0.001]\n",
      "[0.909 0.541 0.670 0.745 0.874] [0.233 0.002 0.082 0.639 0.043] [0.796 0.078 0.002 0.013 0.111]\n",
      "[0.750 0.719 0.038 0.819 0.967] [0.129 0.237 0.000 0.168 0.466] [0.078 0.004 0.050 0.858 0.009]\n",
      "[0.560 0.669 0.072 0.457 0.995] [0.151 0.169 0.000 0.039 0.641] [0.000 0.017 0.919 0.049 0.015]\n",
      "[0.684 0.088 0.260 0.254 0.287] [0.556 0.001 0.068 0.013 0.362] [0.038 0.901 0.018 0.041 0.001]\n",
      "[0.009 0.665 0.524 0.593 0.762] [0.000 0.253 0.156 0.306 0.284] [0.634 0.117 0.032 0.022 0.195]\n",
      "[0.008 0.621 0.088 0.999 0.806] [0.092 0.001 0.049 0.771 0.087] [0.000 0.904 0.002 0.059 0.035]\n",
      "[0.643 0.465 0.451 0.851 0.628] [0.158 0.013 0.108 0.631 0.091] [0.004 0.015 0.008 0.912 0.060]\n",
      "[0.580 0.731 0.136 0.138 0.662] [0.127 0.386 0.142 0.001 0.345] [0.005 0.053 0.000 0.933 0.008]\n",
      "[0.344 0.448 0.035 0.021 0.266] [0.038 0.192 0.106 0.646 0.019] [0.017 0.059 0.008 0.002 0.915]\n",
      "[0.953 0.415 0.739 0.156 0.602] [0.490 0.001 0.508 0.000 0.002] [0.029 0.082 0.253 0.149 0.487]\n",
      "[0.267 0.708 0.689 0.058 0.915] [0.184 0.068 0.018 0.004 0.726] [0.007 0.007 0.941 0.008 0.037]\n",
      "[0.561 0.511 0.437 0.753 0.307] [0.053 0.043 0.007 0.606 0.291] [0.943 0.028 0.011 0.011 0.007]\n",
      "[0.893 0.972 0.150 0.718 0.611] [0.447 0.061 0.003 0.475 0.013] [0.013 0.012 0.036 0.091 0.848]\n",
      "0.058472904112032806\n",
      "Val loss: 0.680083 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.873899  [   64/80000]\n",
      "loss: 0.743216  [ 6464/80000]\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "cur_val_loss = np.inf\n",
    "cur_epoch = 1\n",
    "cur_state_dict = None\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    if test(val_dataloader, model, loss_fn) < cur_val_loss:\n",
    "        cur_epoch = t + 1\n",
    "        cur_state_dict = model.module.state_dict()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a90faf-4fa1-4d50-a1bf-fe2e19323013",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': cur_epoch,\n",
    "            'model_state_dict': cur_state_dict,\n",
    "            }, 'transformer_model_optimal.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
